<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Dayu -- Fast and Low-interference Data Recovery in Very-large Storage Systems</title>
    <link href="/2021/12/12/dayu/"/>
    <url>/2021/12/12/dayu/</url>
    
    <content type="html"><![CDATA[<blockquote><p>原文链接：[Dayu: Fast and Low-interference Data Recovery in Very-large Storage Systems | USENIX](https://www.usenix.org/conference/atc19/presentation/wang-zhufan</p></blockquote><h2 id="摘要">摘要</h2><p>​ 本文试图在对前台流量干扰最小的情况下，加速大规模存储系统中的数据恢复。通过研究现实世界的大型存储系统的I/O和故障跟踪，我们发现，由于系统的规模和不平衡的动态前台流量，现有的恢复协议不能在短时间内生成高质量的恢复策略。为了解决这一问题，本文提出了一种基于时点的恢复协议 —— Dayu，它只安排了预期在一个时点内完成的任务的子集，这种方法减少了计算开销，自然能够应对动态的前台流量。在每个时间段，Dayu 整合了四个关键算法，通过我们的跟踪分析激发启发式来增强现有的解决方案。我们在1,000个节点的真实集群和25,000个节点的模拟中进行的评估都证实，Dayu 能够比现有的恢复协议表现得更好，实现高速度和高质量。</p><h2 id="介绍">介绍</h2><p>​ 本文描述了我们在盘古中加速数据恢复的经验和方法，盘古是一个现实世界的大型存储系统，拥有10K个节点，每个节点有几十TB的存储空间。作为云存储提供商，盘古的所有者阿里云需要向客户承诺数据的持久性（即数据丢失的几率小于阈值）。出于营销方面的原因，所有者有足够的理由来提高数据的持久性，因此与竞争对手相比，它的承诺更有吸引力。这促使我们研究盘古数据恢复是否有可能加速，因为恢复速度是决定数据持久性的因素之一。</p><p>​ 类似于之前的工作，盘古将数据分成块（通常是几十MB），复制这些数据块，并将这些复制分布到不同的节点上。当一个节点发生故障时，盘古会重新复制它的数据块，由于这些数据块的副本分布在不同的节点上，盘古要求所有这些节点并行复制数据块。为了重新复制故障节点的数据块，恢复协议需要为每个数据块调度源、目标和带宽。一个理想的调度算法至少应该实现以下两个目标：</p><p>​ 第一，算法应该生成一个高质量的策略，该策略应该允许在对前台流量影响最小的约束下尽快完成数据的再复制</p><p>​ 其次，调度算法本身的速度要足够高，以免成为数据恢复的瓶颈。</p><p>​ 为了了解现有调度算法的质量和速度，我们分析了盘古实际部署的失败和I/O轨迹。我们发现现有的算法都无法达到可接受的质量和可接受的速度，因为存在以下挑战：</p><ul><li>非常大的规模：盘古最大的部署有超过 10K 个节点和高达 72TB 的存储（约150万个块）每个节点。因此，当一个节点失效时，算法需要决定如何恢复所有这些数据块，每个数据块大约有 10K 个节点作为候选目的地。</li><li>时间限制：考虑到系统的规模，故障节点的数据块可以以高度并行的方式进行重新复制。我们的仿真表明，如果能充分利用空闲带宽，恢复可以在十秒内完成，这意味着调度算法本身应该在几秒内完成。</li><li>不平衡的前台流量和可用数据：我们发现一个双重的不平衡，这对调度的质量提出了挑战。<ul><li>首先，一些节点的前台流量可能比其他节点要大得多</li><li>其次，一些节点可以有更多的数据块用于重新复制。</li></ul></li><li>动态前台流量：前台流量可以随着时间的推移而显著变化。为了应对这种动态流量，恢复协议需要在前台流量发生显著变化时调整其计划，这再次需要快速调度。</li></ul><p>​ 我们对现有调度算法的模拟表明，一方面，简单和分散的算法，如随机选择或两种最佳的随机，可以快速完成调度（即高速），但它们经常导致少量节点过载，增加恢复时间，损害前台流量的性能（即低质量）。另一方面，复杂和集中的算法，如混合整数线性规划，可以有效地利用可用带宽并避免节点过载（即高质量），但考虑到我们的目标系统的规模（即低速度），它们可能需要非常长的时间来计算一个计划。</p><p>​ 本文提出了一种适用于大规模、不平衡、动态存储系统的高速、高质量恢复协议“大禹”。大禹的核心理念来源于观察，为了应对动态的前台流量，<strong>我们需要定期监控前台流量并调整恢复计划</strong>：在这种设计中，对故障节点的所有数据块进行调度不仅计算量大，而且没有必要，因为计划可能在以后进行调整。根据这一观察，大禹整合了一个基于时隙的解决方案：</p><ol type="1"><li>它将时间划分为多个槽，槽的长度由底层存储系统监视和报告空闲带宽的频率决定</li><li>根据这样的报告，大禹试图安排一个子集的块，以便它们可以在当前的时间段内重新复制</li><li>如果由于某种原因，某些块的实际复制时间比预期的长，那么大禹将在下一个时间段重新安排它们</li></ol><p>这种方法有两个好处：<strong>首先，它减少了调度的计算开销，因为在每个时间段，算法只需要调度一个任务子集（在我们的实验中平均约三分之一）</strong>。其次，这个解决方案可以很自然地应对动态的前台流量，因为大禹的决策是基于每个时间段开始时收集的信息。</p><p>为了实现这一想法，大禹整合了四项关键技术，根据我们的观察，对现有算法进行了改进：</p><ul><li>斗式凸壳优化的贪心算法调度任务：大禹利用贪心算法迭代选择利用率最高的候选项作为每个任务的源和目标，直到找到足够的任务来填满一个时间段。为了减少计算开销，大禹引入了凸壳优化[，并进一步提出了桶近似来减小候选集的大小。</li><li>优先考虑具有高空闲带宽但很少可用块的节点：我们的观察表明，如果调度算法决定从其他节点复制它们的块，这样的节点很可能没有得到充分利用。因此，大禹对前面提到的贪心算法进行了改进，采用了以下启发式算法：如果要重新复制的块在该优先级节点上有副本，大禹将该节点指定为源。</li><li>迭代WSS为每个任务分配带宽：为了最小化所选任务的完成时间，大禹对加权洗牌调度算法（WSS）进行了改进：在每次迭代中，大禹使用WSS来识别剩余任务中的瓶颈，并相应地为每个任务分配加权公平的带宽份额，消除瓶颈任务并分配带宽。</li><li>重新调度Straggler：由于对前台流量的错误预测或意外的硬件故障，不可避免地会出现Straggler任务，因此大禹不得不在下一个时间段重新调度它们。Straggler任务不同于新任务，因为我们喜欢保持它们的目的地不变，否则，我们将失去它们现有的进度。大禹首先估计是否值得改变它们的目的地，然后重新计算它们的源并分配带宽。</li></ul><p>​ 我们在实际部署1000个节点的情况下对大禹进行的评估表明，<strong>与盘古相比，大禹的恢复速度提高了2.96倍，并且在恢复过程中，前台流量的p90延迟（即90个百分点的尾部延迟)仅提高了3.7%</strong>。我们的仿真结果表明，大禹的性能优于现有的各种解决方案，可以扩展到25K个节点的集群。</p><h2 id="背景与观察">背景与观察</h2><h3 id="盘古的背景">2.1 盘古的背景</h3><p>​ 盘古是阿里云的底层存储系统，阿里云是亚洲最大的公共云提供商之一。盘古继承了GFS、HDFS、Cosmos和Azure等经典的分布式文件系统架构。它将数据分割成多个块（最常见的块大小为64MB），并将数据块存储在称为块服务器的大量数据服务器上。一个名为 <strong>Meta Server 的元数据服务器维护分布式文件系统的元数据</strong>，例如数据块的位置。由于盘古的规模非常大，盘古整合了多个元服务器，每个元服务器负责元数据的一个子集。此外，盘古整合了一个 <strong>Root Server 将客户端路由到相应的 Meta Server</strong>。为了实现数据的均匀分布，<strong>盘古使用随机或加权随机机制将数据放置在不同的 Chunk Server上</strong>。</p><p>​ 像大多数现有系统一样，盘古复制数据块（大多数数据块有三个副本），所以如果一个节点故障，盘古可以通过从其他副本复制来恢复它的数据块。对于每个要恢复的数据块，盘古需要为数据复制选择一个源和一个目的地：根据副本的数量，通常有几个候选源和大量的候选目的地。当前版本的盘古随机为每个要恢复的数据块选择一个源和一个目的地。在盘古当前的部署中，我们观察到网络带宽通常是<strong>进行此类数据恢复的瓶颈：大多数盘古节点配置1GB或10GB以太网</strong>，其带宽小于磁盘的总带宽；由于成本原因，高速设备（如Infiniband）的部署受到限制。盘古的核心网络交换机采用CLOS拓扑或胖树拓扑组织，因此不会出现超额订阅。根据配置的不同，从核心到机架的链路可能会被过度订阅：如果链路被过度订阅，机架交换机通常是瓶颈；否则，终端主机的网卡就是瓶颈。</p><p>​ 在数据恢复期间，盘古仍在为前台应用服务，这些应用可能会争夺网络带宽。为了减少数据恢复对前台流量的干扰，盘古提供了一种机制来限制节点上一条或一组链路的带宽利用率。通过这种机制，我们可以根据愿意容忍的干扰程度和前台流量的带宽，对恢复流量的带宽设置一个限制。在大禹，我们将每个节点上的恢复流量的带宽限制为 <span class="math display">\[B_{recover}=max(α×B_{total}−B_{foreground},B_{min})\]</span> ​ 式中，<span class="math inline">\(B_{total}\)</span> 是节点的总带宽；<span class="math inline">\(B_{foreground}\)</span> 是前台流量的带宽；<span class="math inline">\(α\)</span> 是控制恢复业务对前台业务干扰的参数。我们将 <span class="math inline">\(α\)</span> 设置为75%，我们的实验表明，使用这个设置将对前台流量的p90延迟产生微不足道的影响。作为一个主要为大文件设计的存储系统，盘古的目标不是优化极端的尾部延迟（例如99.9%），所以这个设置可以满足我们的要求，如果一个人的目标是更小的干扰，他/她可以进一步降低<span class="math inline">\(α\)</span>。<span class="math inline">\(B_{min}\)</span> 是节点为恢复分配的最小带宽，这是为了确保恢复不会太慢。盘古和大禹都将<span class="math inline">\(B_{min}\)</span>设置为30MB/s。</p><h3 id="观察">2.2 观察</h3><p>​ 在本小节中，我们分析盘古部署的工作负载和数据放置，以了解它们如何影响数据恢复。我们从大约3500个节点的数据中心获取这些信息，每个节点有两个1G网卡和11个2TB硬盘。此时，硬盘的总带宽将大于网卡的总带宽。存储系统主要提供ODPS （online data processing service，联机数据处理）服务，包括MapReduce和数据查询。我们分析的内容包括：（1）2018年4月一个 MetaServer 的检查点，记录与数据块大小和分布相关的元数据；（2）未来一周前台流量和后台恢复流量的跟踪。除非另有说明，我们的模拟实验在本文中都是在这个3500个节点的集群上进行的。在第5.2节中，我们研究了在3500个节点之外，大禹的可扩展性。</p><p><img src="/2021/12/12/dayu/dayu_1.png" alt="图1：来自一个3500节点的真实系统的观察"></p><p>我们通过分析得出以下结论：</p><p>​ <strong>观察1：每个节点存储了数十万块数据</strong></p><p>​ 图1(a) 显示了每个节点上块数量的 CDF。我们可以观察到，大多数节点每个节点大约有250K块。这个观察结果说明了两件事：首先，恢复协议需要安排如何在节点故障时恢复如此多的块。其次，当一个节点发生故障时，剩余的每个节点将平均参与大约70个块的复制（250K/3500）。</p><p>​ <strong>观察2：前台流量平均消耗不到带宽的一半</strong></p><p>​ 如果所有可用带宽（使用Equation1计算）都可以用于恢复，系统平均可以在51秒内恢复250K块。</p><p>​ 我们计算了50种不同情况下的最佳恢复时间，假设所有可用带宽都可以利用，并在图1(b)中给出了恢复时间的CDF。该观察结果表明，尽管每个节点故障都有大量的块需要恢复，但大规模系统中的高度并行恢复可以在短时间内恢复这些块，这要求在恢复协议期间进行快速调度。然而，实际的恢复往往需要2-4分钟，是理想恢复时间的2.35 ~ 4.70倍，这促使我们进行进一步的研究。</p><p>​ <strong>观察3：前台流量短期内负载严重失衡</strong></p><p>​ 我们分析的跟踪记录每15秒每个节点的前台带宽。为了了解前台流量是否平衡，我们计算每个时隙中前台带宽的变异系数（CoV，标准差作为平均值的百分比），这是衡量值变化的标准度量。然后在图1(c)和图1(d)中绘制不同时间段 CoV 的分布。如图所示，大部分时间段的 CoV 在0.4 - 0.6之间，这是非常显著的。有趣的是，如果我们以更粗的粒度（如1小时和1天）衡量这种不平衡，这种不平衡会变得更小。</p><p>​ 这样的结果表明，系统在长期内是相对负载均衡的，但在短期内更加不平衡，这给数据恢复带来了挑战：传统的负载均衡技术，如数据迁移，主要针对长期不平衡，因为它们不能经常运行；但数据恢复主要受短期不平衡的影响，因为它可以在几十秒到几百秒内完成。这个观察结果表明，我们的恢复协议必须考虑到这种短期的不平衡，而不依赖于负载平衡技术。</p><p>​ <strong>观察4：一个给定节点上的块副本不均匀地分布在其他节点上</strong></p><p>​ 为了理解给定节点上的块的副本如何在其他节点之间分布，我们定义 <span class="math inline">\(SC_i^j\)</span> 为 <span class="math inline">\(node_i\)</span> 和 <span class="math inline">\(node_j\)</span> 所持有的块的大小，这表明如果 <span class="math inline">\(node_i\)</span> 失败，在恢复过程中 <span class="math inline">\(node_j\)</span> 可以作为源提供多少数据。</p><p>​ 我们首先抽样一个特定的 <span class="math inline">\(node_i=100\)</span>。图1(e)显示了不同 <span class="math inline">\(j\)</span> 值下 <span class="math inline">\(SC_{100}^j\)</span>的分布。我们可以看到，分布的直方图符合钟形曲线：如果我们假设块的放置是随机的，这实际上是可以在数学上证明的（即中心极限定理）。为了理解整个集群中的这种不平衡，对于每个 <span class="math inline">\(node_i\)</span>，我们计算所有 <span class="math inline">\(SC_i^j\)</span> 值的 CoV，然后在图1(f)中绘制所有节点CoV的CDF。</p><p>​ 可以观察到，对于大部分节点，<span class="math inline">\(SC_i^j\)</span> 的分布是不平衡的。为了理解这种不平衡是如何影响恢复的，我们使用盘古的随机节点选择策略（图1(g)）模拟节点100的故障，发现节点 <span class="math inline">\(J\)</span> 和 <span class="math inline">\(SC_{100}^j\)</span> 的输出恢复流量大小之间有很强的相关性。这意味着一个具有少量（很多）公共块的节点在恢复过程中只会做很少（很多）的工作，但是如果该节点有很多（很少）可用带宽，它将得不到充分利用（过载）。</p><p>​ <strong>观察5：前台流量通常在最大带宽的14.4%范围内波动，但有时会发生巨大的变化</strong></p><p>​ 图1(h) 显示了一个节点的前台流量在5小时内的变化情况。差带宽是两个相邻时隙中平均带宽利用率的差值。我们可以观察到，在95%以上的情况下（在图1(h)中的“p2.5”和“p97.5”之间），绝对增量带宽低于 36MB/s，这是最大带宽的14.4%（由于每个节点有两个 1Gb 网卡，所以为 250mb/s）。然而，在剩下的 5% 的情况下，增量带宽可以达到最大带宽的三分之二。尽管这种极端情况的百分比很小，但它们经常发生在恢复中，因为高度并行的恢复通常涉及许多节点。<strong>仿真结果表明，它们在恢复过程中会产生掉队现象，是恢复速度不理想的主要原因之一。</strong></p><h2 id="大禹的概述">大禹的概述</h2><p>​ 在本文的其余部分中，我们将一个数据块的重新复制称为“恢复任务”。大禹通过引入一个名为 ObServer 的集中调度程序，实现了快速的数据恢复和低应用干扰，该调度程序基于时点进行恢复任务调度。Dayu 假设所有的数据服务器定期向观察者报告他们的数据块放置和网络使用情况，所有的元数据服务器将恢复任务的信息发送给观察者。本文的其余部分给出了 ObServer 的调度算法，该算法决定了恢复任务的源、目的和带宽。为了实现高速、高质量的调度，大禹的关键思想是<strong>分批调度恢复任务</strong>，而不是将所有恢复任务一起调度。这种设计选择有以下几个原因：首先，<strong>每个节点通常涉及数十个恢复任务（由观察一得到）</strong>，多批调度任务仍然允许每个节点充分参与每批任务，从而充分利用其可用带宽；其次，<strong>分批调度任务可以很自然地应对动态的前台流量和罕见的测量误差</strong>，因为大禹在观察到前台流量的任何变化时，都可以在下一批进行调整；最后，<strong>分批调度可以很自然地减少调度算法的计算开销</strong>，因为对于每批，算法只需要调度任务的一个子集。</p><p><img src="/2021/12/12/dayu/dayu_2.png" alt="大禹时效性调度"></p><p><img src="/2021/12/12/dayu/dayu_t1.png" alt="表1：表示"></p><p>​ 为了实现这个想法，如图2所示，大禹将整个恢复时间划分为多个固定长度的时间片（在本文中称为时隙）。在时隙开始时，obServer收集数据服务器的最新状态。<strong>使用获得的状态，obServer选择并调度该时隙中的恢复任务子集</strong>，包括那些在最后一个时隙中调度但尚未完成的恢复任务。为了充分利用可用带宽，大禹将多个时间段进行重叠，以便在n−1时间段结束前对n号槽位进行信息收集和任务调度。时间段的长度由底层存储系统收集和报告状态的频率决定。如2.1节所述，数据恢复的瓶颈不是终端主机的网卡就是机架交换机的网卡，为了简化描述，本文假设终端主机的网卡是瓶颈，可以很容易地扩展到支持瓶颈机架交换机。表1列出了本文使用的表示法。</p><h3 id="目标">3.1 目标</h3><p>​ 大禹努力实现以下目标</p><ul><li><p>目标1：尽可能多地利用可用带宽。这是一个自然的目标，以减少整体恢复时间。如果我们充分利用一个时隙中的可用带宽，在该时隙中可以复制的块的总大小(S)为： <span class="math display">\[S=min(∑_{i∈Nodes}B^i_{recover\_in} , ∑_{i∈Nodes}  B^i_{recover\_out}) × T_{timeslot}\]</span></p></li><li><p>目标2：在目标时隙中完成尽可能多的任务。我们希望调度的任务能够在目标时间段内实际完成：否则，我们必须重新调度它们，这增加了计算开销。这个目标可能看起来和第一个目标相似，但它不是：第一个目标建议我们超额订阅网络带宽（即调度比带宽所能处理的更多的任务），这样，如果前台流量下降，我们仍然可以利用这些额外的可用带宽；然而，第二个目标建议我们少订阅网络带宽，这样即使前台流量增加，我们仍然可以完成预定的任务。因此，大禹不得不在这两个目标之间进行权衡。</p></li><li><p>目标3：最小化明显掉队的机会。由于我们无法准确预测未来的前台流量，因此不可避免地会出现掉队现象。我们更喜欢许多小的掉队者而不是一些重要的掉队者，因为许多小的掉队者可以被重新安排并并行执行，从而最小化恢复时间。但是，这个目标和第二个目标显然是矛盾的，所以大禹也需要权衡。</p></li></ul><h3 id="大禹算法概述">3.2 大禹算法概述</h3><p>​ 为了实现这些目标，大禹整合了四种关键技术，通过基于我们观察的启发式和近似算法来增强现有算法：</p><ul><li><p>一种贪婪算法，通过桶凸壳优化来选择每个恢复任务的源和目的地</p></li><li><p>基于启发式算法的节点优先级与少数公共块与失败节点，但高可用带宽</p></li><li><p>为每个任务分配带宽的迭代WSS算法</p></li><li><p>一种基于启发式的算法，以最小化重新调度掉队任务的代价</p></li></ul><h2 id="大禹">大禹</h2><h3 id="选择源和目的">4.1 选择源和目的</h3><p>​ 大余反复扫描所有任务，确定每个任务的源和目的，直到找到足够的任务来填充（公式2）。一个任务的候选源包括所有持有相应块副本的节点；任务的候选目的地包括不在其源的同一机架中的所有节点。为了实现第三节给出的目标，大禹采用了贪婪算法：</p><p>​ 对于每个任务，大禹在其候选源和目标中选择利用率最高的节点；</p><p>​ 如果大禹发现即使是最没有被充分利用的候选也会饱和，大禹就会跳过这个任务。我们需要回答的第一个问题是如何定量地度量节点的利用率。我们已经尝试几个选项,通过模拟,我们决定使用预期的任务完成 <span class="math inline">\(\frac{c_{in/out}}{B_{recover\_in/out}}\)</span> (<span class="math inline">\(c_{in/out}\)</span> 是传入/传出的总大小任务分配给该节点）作为指标来评估一个节点的利用率，因为这个指标达到前两个目标之间的平衡。</p><p>​ 因此，在为任务 t 选择源时，大禹扫描其所有候选节点，并选择 <span class="math inline">\(\frac{s_t+c_{out}}{B_{recover\_out}}\)</span> 最小的节点作为源。这种扫描在计算上并不昂贵，因为大多数块有三个副本，其中一个已经丢失了。之后，Dayu会检查分配任务给源是否会使源饱和，即它的 <span class="math inline">\(\frac{s_t+c_{out}}{B_{recover\_out}} &gt; T_{timeslot}\)</span> ：如果是，Dayu将会丢弃任务t，因为这意味着在这个时间段没有办法完成任务。</p><p>​ 同样，当为任务 t 选择目的地时，大禹选择 <span class="math inline">\(\frac{s_t+c_{in}}{B_{recover\_in}}\)</span> 最小的节点。但是，由于候选目的地的数量很大，简单地扫描所有候选目的地的计算量很大。更糟糕的是，贪心算法不能并行化，因为每次迭代都依赖于前一次迭代的结果。我们在一个3500节点的集群上的模拟表明，简单地扫描每个任务的所有候选目的地的速度只能达到每秒不到30000个任务。根据我们的统计，在一个时间段内，大余通常可以完成6万-15万项任务，这意味着单纯的扫描本身需要2-5秒，这并不理想。为了解决这个问题，我们结合了动态凸包优化来加速计算。</p><p><img src="/2021/12/12/dayu/dayu_3.png" alt="图3：通过动态凸包优化减少计算开销"></p><p>​ 凸包优化的形式化描述可以参考，这里我们给出了一个直观的描述。对于每个幸存的 <span class="math inline">\(node_i\)</span>，我们在笛卡尔坐标系中绘制一个点<span class="math inline">\((B^i_{recover\_in},c^i_{in})\)</span>，如图3(a)所示。然后，对于大小最大的task，我们在图3(a)中绘制另一个点<span class="math inline">\((0,−s_t)\)</span>。然后，我们从 <span class="math inline">\((0,−s_t)\)</span> 到彼此的点画一条线：由于每条线的斜率为<span class="math inline">\(\frac{c^i_{in}+s_t}{B^i_{recover\_in}}\)</span>，为任务 t 找到目标节点等同于找到斜率最低的线。我们可以保持一个动态凸包来快速搜索斜率最低的直线。在二维空间中，凸壳就像一根橡皮筋，将所有的点紧紧地包裹起来，下面的凸壳就是这个凸壳的下部。</p><p>​ 我们可以保持一个动态凸包来快速搜索斜率最低的直线。在二维空间中，凸壳就像一根橡皮筋，将所有的点紧紧地包裹起来，下面的凸壳就是这个凸壳的下部。我们将下凸壳的点集称为 <span class="math inline">\(H\)</span>（这里我们将 <span class="math inline">\(H\)</span> 中的点连接在一起，形成图3(a)所示的下凸壳）。<span class="math inline">\(H\)</span> 中的点是逆时针连接的。那么对于在集合 <span class="math inline">\(H\)</span> 中有前导点和后继点的点 <span class="math inline">\(p_h\)</span>，直线 <span class="math inline">\(p_{h−1}→p_h\)</span> 的斜率必须小于或等于直线 <span class="math inline">\(p_h→p_{h+1}\)</span> 的斜率。利用二分搜索的时间复杂度为 <span class="math inline">\(O(log|H|)\)</span>，我们可以找到与点 <span class="math inline">\((0, −s_t)\)</span> 的连接斜率最小的节点集 <span class="math inline">\(H\)</span>。</p><p>​ 在大禹分配任务到 <span class="math inline">\(node_i\)</span> 后，它的 <span class="math inline">\(c^i_{in}\)</span> 增加 <span class="math inline">\(s_t\)</span>。因此，大禹需要调整节点 <span class="math inline">\(i\)</span> 的点以及下凸壳 <span class="math inline">\(H\)</span>：当点 <span class="math inline">\(p_h\)</span> 向上移动时，大禹识别原始 <span class="math inline">\(H\)</span> 中 <span class="math inline">\(p_h\)</span> 的前体 <span class="math inline">\(p_{h−1}\)</span> 和后续 <span class="math inline">\(p_{h+1}\)</span>，并扫描它们之间的所有点，以找到 <span class="math inline">\(H\)</span> 的新成员。凸包优化将目标节点的扫描复杂度由线性降低为次线性，且不影响贪心算法的结果。</p><p>​ 我们进一步提出了一个近似解来减少下凸壳的候选集，从而提高了算法的速度。如图3(b)所示，我们将可用的传入带宽范围划分为多个相等的桶。如果 <span class="math inline">\(node_i\)</span> 和 <span class="math inline">\(node_j\)</span> 在同一个桶中，则认为它们具有近似相同的可用带宽，即 <span class="math inline">\(B^i_{recover\_in} ≈ B^j_{recover\_in}\)</span>。不失一般性，我们设 <span class="math inline">\(c_i&gt;c_j\)</span>。那么，<span class="math inline">\(node_i\)</span> 不可能是下凸壳的成员。因此，只有同一桶内的最低节点才能成为下凸壳的成员。所有这些最低的节点（图3(b)中的空心圆）形成一个简化的候选集，记为 <span class="math inline">\(C\)</span>。我们可以用这个简化的候选集<span class="math inline">\(C\)</span> 构造凸壳<span class="math inline">\(H\)</span>，而不是从节点的全部集合。大禹给一个节点分配任务后，会对该节点的点和减少的候选集进行调整。</p><p>​ 桶的大小决定桶近似的还原程度。在我们的实验中，我们使用 1 MB/s 作为的桶大小，我们的模拟显示平均减少因子为 22.8，因此，大禹可以在一秒内完成约21万个块的源和目的地的选择，这比普通扫描快7倍。</p><p>​ 这样的桶近似当然会给贪心算法带来不准确性，但由于测量误差和前台流量的波动，这种不准确性已经存在。因此，只要桶的大小很小，我们的近似就不会显著增加这种不准确性。</p><h3 id="未充分利用节点的优先级排序">4.2 未充分利用节点的优先级排序</h3><p>​ 我们对贪婪算法的模拟揭示了与我们的观察3和4相同的问题：具有高可用带宽的节点，但只有少量可用块可能没有得到充分利用，这违背了我们的第一个目标。在本文的其余部分，我们称之为未充分就业节点。例如，假设节点A有一个可用的输出带宽 50MB/s，它可以是任务 1 和任务 2 的源；节点B的可用输出带宽为 60MB/s，可以作为任务 1-4 的源；所有任务的大小相同。在这个例子中，最佳的调度应该让A是任务1和2的源，而B是任务 3 和 4 的源。但是，如果贪心算法先扫描任务1，它会将任务1分配给节点B，因为此时B比A有更多可用带宽。</p><p>​ 这个观察结果表明，对于在未充分利用的节点中拥有副本的块，最好使用未充分利用的节点作为源。为了实现这个目标，我们结合了一个分布式驱动的优先排序策略：obServer首先根据可用的输出带宽降序排序所有节点，然后根据公共块的总大小升序排序所有节点。然后，obServer从这两个节点列表中分别选取第一个β（在我们的典型设置中为5%)节点组成两个集合，并通过计算这两个集合的交集得到未充分利用的节点集。接下来，observer选择在未充分利用的节点中具有副本的所有恢复任务，并将它们放入一个称为“优先队列”的队列中；theobserver把剩下的任务放到另一个叫做“正常队列”的队列中。</p><p>​ 我们修改了贪心算法(§4.1)，以结合这种启发式：观察者将首先扫描优先队列中的任务，并直接使用相应的未充分利用的服务器作为源，而不是使用最未充分利用的候选服务器。有两种极端情况：</p><ul><li>一个优先级任务可能在多个未充分利用的服务器中拥有副本。在这种情况下，观察者选择其中最没有得到充分利用的一个</li><li>虽然很少，但有可能未充分就业的服务器是饱和的。在这种情况下，观察者将优先级排序的任务降级到正常队列中，这样以后我们仍然可以尝试它的非优先级候选任务</li></ul><p>​ <strong>开销</strong>：在搜索未充分利用的节点时，大禹维护两个堆，其键分别为可用的输出带宽和公共块的总大小，其值为节点的 id。obServer首先构建这两个堆，这是 <span class="math inline">\(O(n)\)</span> 操作（n是节点数），然后从这两个堆中弹出 5% 的条目，每个弹出一个 <span class="math inline">\(O(logn)\)</span> 操作。我们的实验表明，堆积10,000个条目，然后弹出其中的 5% 只需要几毫秒。</p><h3 id="为每个任务分配带宽">4.3 为每个任务分配带宽</h3><p>​ 给定每个恢复任务的源和目的地，我们需要回答每个任务应该以多快的速度进行。一个简单的解决方案是使用 <span class="math inline">\(B_{recover\_in/out}\)</span> 对一个节点内的所有任务设置一个粗粒度限制，并让它们竞争带宽。然而，我们的实验揭示了这种方法的两个问题：第一，当源的输出限制大于目的的输入限制时，这种方法可能会导致拥塞。虽然TCP最终可以解决这种拥塞，但它会导致数据包丢失，恢复速度变慢。</p><p>​ 其次，竞争可能会导致一个任务比其他任务明显慢，导致明显的掉队和违反我们的第三个目标。因此，在这一步中，大禹试图为一个时隙中的每个任务设置一个恒定的速率，以最大限度地利用带宽。回想一下，我们假设终端主机的网卡是瓶颈，所以这个步骤只考虑终端主机的带宽利用率。即便如此，这仍然是一个具有挑战性的问题，因为为一个任务分配带宽将消耗两边的带宽。</p><p>​ Dayu的解决方案是基于加权洗牌调度（WSS），这是一种成熟的网络调度算法，用于在MapReduce 中调度像数据洗牌这样的大数据流。WSS 的关键思想是，为了在同一时间完成所有的成对传输，它保证：</p><ul><li>传输速率与每次传输的数据大小成比例</li><li>至少有一个链路被充分利用</li></ul><p>​ 使用 WSS 时，只有瓶颈链接(相当少数)得到充分利用，而其他所有链接都有剩余的带宽。在我们的场景中，然而，WSS 并不理想：当考虑不可预测的增长前台流量,这可能会导致一个non-bottleneck链接成为瓶颈的一个时隙，WSS可能导致浪费带宽，因为大禹可以利用更多的带宽这个链接的开始。</p><p>​ 为此，大禹引入了一个迭代的 WSS 解决方案，为每个任务分配带宽。其核心思想是在不延迟瓶颈任务的情况下，尽早完成其他任务，从而减少其完成时间，提高带宽利用率。按照这个思路，如果运行一次 WSS 迭代后还有剩余带宽，大禹就会使用另一次 WSS 迭代来识别下一个瓶颈，并分配剩余带宽。</p><p>​ 具体来说，Dayu为每个节点维护剩余的传入和传出带宽 <span class="math inline">\(B^i_{remain\_in}\)</span> 和 <span class="math inline">\(B^i_{remain\_out}\)</span>，其初始值为 <span class="math inline">\(B^i_{recover\_in}\)</span> 和 <span class="math inline">\(B^i_{recover\_out}\)</span>。在每次迭代中，大余首先找到 <span class="math inline">\(\frac{c^i_{in}}{B^i_{remain\_in}}\)</span> 或 <span class="math inline">\(\frac{c^i_{out}}{B^i_{remain\_out}}\)</span> 最长的节点，记为 <span class="math inline">\(T^*\)</span>：相应的任务是瓶颈。然后，Dayu为每个任务分配 <span class="math inline">\(T^*\)</span> 带宽，表示为了最小化完成时间，必须为瓶颈任务分配一个加权的公平带宽份额，使份额的权重与 <span class="math inline">\(s_t\)</span> 成比例。之后，大禹对于每个<span class="math inline">\(node_i\)</span> 将剩余带宽更新为 <span class="math inline">\(B^i_{remain\_in} −= \frac{c^i_{in}}{T^∗}\)</span> 和 <span class="math inline">\(B^i_{remain\_out} −= \frac{c^i_{out}}{T^∗}\)</span>，从它们对应的节点中移除瓶颈任务，并更新这些节点的 <span class="math inline">\(c_{in/out}\)</span> 值。然后Dayu带着剩余的任务移动到下一个迭代，直到没有剩余的任务或者剩余的任务在分配的带宽下有一个可接受的传输时间（即小于或等于一个时隙的长度)。注意，如果一个任务经历多次迭代，那么它分配的带宽就是每次迭代中分配的带宽的总和。</p><p>​ 迭代 WSS 克服了 WSS 的缺点：由于迭代 WSS 试图分配所有的带宽，当有任务可以利用这些带宽时，系统不可能浪费带宽。</p><p>​ 我们的实验表明，对于一个3500节点的集群，每次迭代的时间最多为 15ms。由于动态凸包节点选择算法保持大多数节点的 <span class="math inline">\(\frac{c}{B}\)</span> 值接近，迭代的 WSS 算法通常可以在5次迭代（即75ms)内完成，这是可以接受的。</p><h3 id="重新调度分散任务">4.4 重新调度分散任务</h3><p>​ 由于工作量估计不准确、调度不佳、硬件异常等原因，在一个时隙结束时，有些任务无法完成。Dayu必须在下一个时隙重新调度这样的straggler任务，但不能简单地将其视为新任务，因为改变一个straggler任务的目的地需要从头重新传输任务，造成带宽的浪费。因此，如果可能的话，大禹应该避免改变目标——这是新任务没有的约束。</p><p>​ 识别掉队。回想一下，Dayu重叠了不同的时隙，因此当前时隙的调度阶段发生在最后一个时隙结束之前的一小段时间（表示为 <span class="math inline">\(T_{schedule}\)</span> ）（图2）。因此，大禹必须预测哪些任务会成为掉队者：对于一个未完成的任务，大禹利用它目前的速度来估计它到最后一个时间段结束时的速度；如果在估计的速度下不能完成任务，大禹就把这些任务放到散列集合中。</p><p>​ 预测当然是不准确的。如果大禹将一个任务标记为straggler，而实际上该任务在最后一个时间隔完成，那么相应的节点就会简单地忽略大禹安排的新的传输计划。反之，如果未标记为straggler的任务在最后一个时间隔内无法完成，则相应的节点将无法得到新的传输计划，因此将坚持原来的计划。这两种情况都可能导致效率低，但由于 <span class="math inline">\(T_{schedule}\)</span> 比 <span class="math inline">\(T_{timeslot}\)</span> 小得多，这两种错误的识别在我们的实验中影响不大。</p><p>​ 调度掉队。首先，Dayu将检查散列集本身是否会使当前时隙中的某些节点饱和。如果有，那么obServer 迭代地从每个饱和的节点中驱逐完成最少的任务，直到它不再饱和。那些被驱逐的任务被分为两组：从它们的来源驱逐的任务和从它们的目的地驱逐的任务。它们以不同的方式重新安排。</p><ul><li><p>对于第一组中的每一个straggler任务，观察者选择一个源和一个传输速率（与一个新任务相同)，同时保持目标不变，这意味着任务可以从当前的进度恢复。</p></li><li><p>对于第二组中的每个straggler任务，观察者将其重新调度为一个新任务。</p></li></ul><p>​ 对于未驱逐的straggler任务，大禹保持其源和目的地不变，并使用迭代 WSS 算法分配带宽。他们可以从当前的进程中恢复。</p><p>​ 与将掉队者视为新任务相比，大禹试图减少重传数据，因为它只改变了第二组掉队者（相当少数)的目的地，并重传他们的数据。</p><p>​ 实验结果表明，与让失速者继续进行原计划相比，引入失速者调整使总体恢复速度提高了15.6%。还应该注意的是，如何检测和报告慢硬件是一个正交问题[25-27]。大禹假设系统有一些机制来测量和报告每个节点的实际带宽。</p><h2 id="评估">评估</h2><p>我们的评估试图回答以下问题：</p><ol type="1"><li>大禹多快可以完成一次典型的全节点恢复，大禹在后台和前台之间引入了多少干扰？——负面影响(§5.1)</li><li>大禹能发展成更大的系统吗？—— 可扩展性 (§5.2)</li><li>在大禹，每一项关键技术带来多少效益？(§5.3)</li><li>参数的设置对大禹的性能有何影响？(§5.4)</li></ol><p><strong>实施</strong></p><p>​ 我们通过修改盘古的MetaServers、RootServer 和 ChunkServers，并将大余的 ObServer 引入盘古，在盘古上实现大余，如图4所示。ObServer能够感知所有恢复任务的信息，以及RootServer提供的全局信息，比如每个 ChunkServer 上的块位置和网络利用率。盘古每15秒监视和报告ChunkServer 的状态，此实现的时隙长度设置为15秒。在盘古中检测到一个节点故障时，MetaServers 会将故障节点的所有数据块报告给观察者，观察者会安排如何重新复制这些数据块。然后，ObServer 指示 Chunkservers 执行恢复任务（即重新复制数据块)。最后，在恢复任务完成后，observer 更新 Metaservers 以反映新重新复制的块的位置。</p><p><strong>试验设备</strong></p><p>​ 我们已经在一个1000节点的集群上部署了基于盘古的大禹实现。每个节点有2个12核Intel E5-2630处理器、96GB DDR4内存、2个10Gbps网卡、10 或 112TB硬盘和Linux 3.10.0。由于我们的跟踪是从具有1Gbps网卡的集群中收集的，但是我们的测试床配备了10Gbps网卡，所以我们在测试床中添加了流量控制，以便每个网卡只能使用1Gbps带宽。我们还搭建了一个模拟环境，在3500个节点以上的规模下测试大禹。我们在具有两个16核Intel E5-2620处理器、64GB DDR4内存和Linux 3.10.0的服务器上运行模拟。</p><p><strong>方法</strong></p><p>​ 对于真实系统上的实验，我们通过关闭一个 ChunkServers 来触发数据恢复。当执行恢复时，我们回放从真实集群系统收集的跟踪(§2.2)。由于我们的测试集群小于跟踪所来自的集群，我们通过调整或重定向一些请求来重塑跟踪以适应集群大小，同时保持读和写的比例、每个节点上的压力以及节点之间的不平衡程度。我们记录恢复时间以及前台和恢复流量之间的干扰，这是通过比较有和没有恢复流量的前台请求的p90延迟（即90%的尾部延迟）来测量的</p><p>​ 在仿真实验中，我们通过将chunk信息发送给Dayu来模拟chunkserver的故障。因为我们没有实际运行系统，所以我们需要模拟前台和恢复流量之间的干扰。由于系统的规模，请求级仿真需要很长时间，所以我们使用流级仿真，如[29,30]。它模拟每个链路的带宽利用率，并根据前台和恢复流量信息定期更新利用率。我们将干扰因子定义为过载流量大小与链路带宽的比值，如下所示： <span class="math display">\[B^i_{overload} = max(B^i_{recover}+B^i_{foreground} −75\%×B^i_{total},0)\]</span></p><p><span class="math display">\[F_{interference} = \frac{∑_{i∈Nodes}B^i_{overload}}{∑_{i∈Nodes}B^i_{total}}\]</span></p><p>​ 我们定义这样一个干扰因素的原因是，如果总带宽利用率超过NIC带宽的75%，前台延迟将显著增加。为了定量地理解这个模拟的干扰因素，我们将它们映射到现实世界实验中的p90延迟(§5.4)：简短的结论是，小于2%的干扰因素表示非常小的干扰，接近或大于6.5%的干扰因素表示非常大的干扰。</p><p>​ 在模拟实验中，我们随机选取50对失效节点及其失效时间，模拟了50种失效案例。对于每个算法，我们在所有50种情况下模拟其性能，并报告其平均性能数。</p><p>​ 在我们接下来的实验中，图5展示了来自真实系统的结果，其他的图展示了来自模拟实验的结果。</p><p><strong>比较</strong></p><p>​ 在真实系统上的实验中，我们将大余复制策略与盘古原始的复制策略进行了比较。盘古原始复制策略采用磁盘利用率感知的随机数据放置和静态速率控制。我们使用三种配置spangui -slow（将恢复流量限制为30MB/s，这是生产系统中的默认配置)、Pangumid（90MB/s）和 Pangu -fast （150MB/s）作为基线。</p><p>​ 在仿真实验中，我们比较了大余与先进系统(表2)中使用的不同调度算法，但MCMF除外，因为它的优化求解器不是开源的。为了公平起见，我们保留了大禹的节点优先排序和散差调整部分，并插入了不同的节点选择和带宽分配算法。</p><p>​ 具体来说，在选择恢复任务的目的地时，我们将大禹的桶动态凸壳算法（C）与以下两种算法进行了比较：</p><ul><li>Random（R），随机选择一个节点作为传输源和目的地；</li><li>双随机最佳（Best-of-two-random, B2R），首先随机选择两个 chunkserver，然后选择负载较轻的一个作为源或目的地；</li><li>加权随机（Weighted random, WR），以可用带宽作为权值，随机选择节点；</li><li>Greedy1（G1），它扫描所有的候选 ChunkServers，然后在我们的场景中找到具有minimalc B.5 的 Greedy2（G2），它通过维护一个红黑树来选择负载最轻的 ChunkServer。</li></ul><p>​ 所有贪心算法，包括Dayu，都是使用单个线程执行的；所有基于随机的算法都使用16个线程执行。注意，尽管随机算法可以通过分布来达到更高的速度，但在我们的实验中，我们发现它们的速度并不是瓶颈。我们还使用最先进的 MILP 求解器 Gurobi 测试了 MILP 算法，但发现它只能完成小规模集群的计算；对于一个3500节点且只有2000个任务的集群，它在125秒后无法完成计算，因此我们不报告其结果。当确定每个任务的速率时，我们将Dayu的迭代 WSS（W）与基于期限的分配（DA）进行比较，DA分配一个时间间隔任务的速率，以便一个任务可以在一个时间间隔内完成。</p><h3 id="整体性能">5.1 整体性能</h3><p>​ 对现实世界系统的评估。图5显示了恢复期间前台请求的恢复时间和p90延迟。在这个测试中，我们关闭一个服务器以创建15TB的数据来恢复，大约有990个幸存的 ChunkServer负责恢复。为了比较，我们在图5中添加了一个“理想”条目，它估计了假设所有可用带宽（α=75%）都可以利用的最佳恢复时间，并且不引入对前台流量的干扰（即前台延迟与没有恢复的延迟相同）。</p><p>​ 从图中可以看出，大余达到了接近最佳的恢复速度，且干扰小。首先，大宇正在接近理想的恢复速度，因为它的恢复时间比“理想”长1.19倍：分别比 Pangu-slow （默认）和 Pangu-mid 配置快2.96倍和1.24倍。与 Pangu-fast 配置相比，虽然大余恢复速度略慢（0.93倍），但对前台流量的干扰要小得多。考虑到恢复流量对前台流量的干扰，大宇的p90延迟仅比“理想”长1.04倍：Pangu-slow对p90延迟的干扰略低，与“理想”几乎相同；Pangu-mid 和 Pangu-fast 的p90延迟比“理想”高4.23-48.14倍，产生了不可接受的干扰。由于 Pangu-mid 和 Pangu-fast 对前台流量的干扰较大，在生产集群中很少使用。综上所述，与盘古不同设置相比，大宇的恢复时间和干扰都接近最优。</p><p><strong>仿真系统的评估</strong></p><p>​ 图6为仿真实验结果。再次，与其他算法相比，大禹在恢复速度和干扰之间取得了很好的平衡。</p><p><img src="/2021/12/12/dayu/dayu_6.png" alt="图6：模拟数据恢复Dayu使用C+W)"></p><p>​ 在恢复速度方面，大宇将动态凸包节点选择与迭代WSS (C+W）相结合，在所有算法中恢复时间最短，比理想恢复时间长1.14倍。与其他算法相比，动态凸包节点选择算法恢复速度最快，比排名第二的G1算法快1.12倍。需要注意的是，虽然G1在这个实验中接近于Dayu，但由于它的高计算开销，它并不能很好地扩展(§5.2)。对于大余等基于贪心的算法，迭代WSS略快于基于期限的分配，因为迭代WSS可以在任务较少的情况下提前完成最后一个时隙，而迭代WSS必须在最后一个时隙的末尾完成任务。对于基于随机的算法，这种影响是不明确的，因为恢复速度主要取决于源和目的地的选择。</p><p>​ 在前台干扰方面，大宇有可以接受的干扰因子（回忆一下，2%的干扰因子很小，大于6.5%的干扰因子是不能接受的）。在相同的带宽分配策略下，大余的节点选择算法和其他贪心算法的干扰比随机算法略大，因为贪心算法通常会占用更多的估计可用带宽。当对前台流量的估计存在一定误差时，干扰会稍微大一些。在相同的节点选择算法下，迭代WSS始终比基于期限的分配(DA)带来更小的干扰。</p><h3 id="可扩展性">5.2 可扩展性</h3><p>​ 我们评估了大禹超过3500个节点的可扩展性。为了衡量不同算法的全部能力，我们假设有无限多个恢复任务，并模拟每个算法在20个时间段内可以恢复多少数据。由于模拟聚类的规模大于我们观察到的聚类，我们根据收集到的痕迹的统计数据随机生成块放置；我们从一个真实节点随机选取一个模拟节点的前台轨迹。</p><p><img src="/2021/12/12/dayu/dayu_7.png" alt="dayu_7"></p><p>​ 如图7所示，大禹可以扩展到25000个节点，至此，大禹的性能比其他算法都要高。我们不测试更大的规模，因为它们离我们的目标（10K节点）太远了。除了大禹之外，所有随机算法的扩展性都很好，这是意料之中的，尽管它们的性能没有大禹那么好。G1不能扩展到超过5,000个节点，因为它的计算开销很大。需要注意的是，作为贪婪算法，大禹和G2最终会在某一点停止缩放，因为它们的集中计算，但至少对于我们现在和不久的将来的目标规模，仿真表明，大禹足够快，可以提供更好的质量。</p><h3 id="个别技术效果">5.3 个别技术效果</h3><p><img src="/2021/12/12/dayu/dayu_8.png" alt="图8：未充分利用节点优先排序(P)和重新调度掉队的影响(A)"></p><p>​ 我们进一步研究了在第4.2和4.4节中描述的未充分利用节点的优先排序(P)和重新调度掉队节点(A)的影响。我们使用带有凸包节点选择(C)和迭代WSS带宽分配(W)的Dayu作为基线(C+W)，扫描没有优先级的任务，并按照原计划执行掉队者(即P和A被禁用)。请注意，在此基线中，Dayu知道这些掉队者，并将使用它们的信息来安排当前时间段，但不会重新安排掉队者。图8显示了Dayu在P和A情况下的调度结果，从图中可以看出，对掉队者的再调度对性能非常敏感:与基线(C+W)相比，对掉队者(C+W+A)的再调度减少了15.6%的恢复时间，同时也减少了干扰。虽然未充分利用的节点的优先级在不重新调度掉队者的情况下效果有限，但当已经配置掉队者重新调度时，它将恢复速度加快7.2%(将“All”与C+W+A的情况进行比较)。</p><h3 id="关键参数的影响">5.4关键参数的影响</h3><p>​ 最后，我们测量了大禹的关键参数的影响。第一个是方程1中的 <span class="math inline">\(α\)</span>，它控制恢复流量对前台流量的干扰。图9(a)绘制了在步长为5%时，<span class="math inline">\(α\)</span> 的恢复时间和干扰因子从65%增加到85%。可以看出，<span class="math inline">\(α\)</span> 越大，恢复时间越短，但干扰因子越大。在这张图中，我们进一步将这些模拟干扰因素映射到现实世界中的p90延迟，以便我们可以定量地了解模拟干扰因素的值。我们决定使用75%的 <span class="math inline">\(α\)</span> 值主要是基于这些p90潜伏期的现实世界的实验：当 <span class="math inline">\(α=75%\)</span> 时，Dayu达到接近最佳的恢复时间和p90潜伏期(§5.1)；当 <span class="math inline">\(α=80%\)</span> 时，尽管Dayu将恢复时间减少了9.1%，但它几乎将前台流量的p90延迟提高了三倍。</p><p><img src="/2021/12/12/dayu/dayu_9.png" alt="dayu_9"></p><p>​ 下一个参数 <span class="math inline">\(β\)</span> 表示在 Section4.2 中选择未充分利用的 ChunkServers 时，从两个排序列表中选择的节点的比例。我们将 <span class="math inline">\(β\)</span> 由0%变为10%，步长为2.5%。如图9(b)所示，<span class="math inline">\(β\)</span> 值对干扰因子的影响不显著，当 <span class="math inline">\(β\)</span> 值为5%时恢复时间最短，这也是大宇将 <span class="math inline">\(β\)</span> 值设为5%的原因。</p><p>​ 另一个重要的参数是时隙的长度(时间间隔)，但由于这个参数影响盘古的总体开销，我们不被允许在生产系统中更改它，因此我们无法记录和分析不同时隙的跟踪。总的来说，更短的时间间隔会让大宇受益，因为它可以更快地对前台波动做出反应，但会增加盘古的开销。</p>]]></content>
    
    
    
    <tags>
      
      <tag>论文翻译</tag>
      
      <tag>云</tag>
      
      <tag>数据恢复</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>项目记录 —— Yapi 部署问题记录</title>
    <link href="/2021/11/23/Yapi%E9%83%A8%E7%BD%B2%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
    <url>/2021/11/23/Yapi%E9%83%A8%E7%BD%B2%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h2 id="需求">需求</h2><ul><li><p>Yapi主要负责对项目的Api文档记录和测试</p></li><li><p>由于项目中主要是Api的开发，所以在内网搭建Api管理平台成为较大的需求</p></li><li><p>选择Yapi是由于用的人较多和部署比较方便（如果没有Bug）</p></li></ul><h2 id="yapi内外部署">Yapi内外部署</h2><h3 id="部署前环境描述">部署前环境描述</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">OS: Windows 10<br><span class="hljs-meta"></span><br><span class="hljs-meta">&gt;</span><span class="bash"> node --version</span><br>v16.13.0<br><span class="hljs-meta"></span><br><span class="hljs-meta">&gt;</span><span class="bash"> npm --version</span><br>8.1.0<br></code></pre></td></tr></table></figure><h3 id="简单部署">1、简单部署</h3><p>按照官方文档 <a href="http://yapi.smart-xwork.cn/doc/devops/index.html">内网部署 (smart-xwork.cn)</a></p><p>一开始选择了懒人法也是推荐法，可视化部署</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">npm install -g yapi-cli --registry https://registry.npm.taobao.org<br>yapi server<br></code></pre></td></tr></table></figure><p>一开始安装到yapi服务启动都是没有问题的</p><p>按照提醒 <code>在浏览器打开 http://0.0.0.0:9090 访问</code></p><p>即通过浏览器访问 <code>http://127.0.0.1:9090/</code></p><p>打开界面，提交表单初始化平台部署</p><p><img src="/2021/11/23/Yapi%E9%83%A8%E7%BD%B2%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/config_page.png" alt="配置界面" style="zoom:67%;"></p><p><img src="/2021/11/23/Yapi%E9%83%A8%E7%BD%B2%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/waiting.png" alt="提交结果" style="zoom:67%;"></p><p>等待配置时间过长，发现异样，打开cmd检查，果然有错误</p><p>错误日志为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">&lt;ref *1&gt; Error: getaddrinfo ENOTFOUND yapi.demo.qunar.com<br>    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:71:26) &#123;<br>  errno: -3008,<br>  code: &#x27;ENOTFOUND&#x27;,<br>  syscall: &#x27;getaddrinfo&#x27;,<br>  hostname: &#x27;yapi.demo.qunar.com&#x27;,<br></code></pre></td></tr></table></figure><p>寻找了一下大佬的方案后，只在一 <a href="https://github.com/YMFE/yapi/issues/16#issuecomment-751991231">Github issues</a> 中找到了解决流程</p><p>便是接下来的 <strong>命令行部署</strong></p><h3 id="命令行部署">2、命令行部署</h3><p>先构建一个项目文件夹 如 <code>D:\Project\Yapi</code></p><p>在 <code>yapi</code>中打开 CMD <code>clone</code> yapi 项目</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">clone</span> https://github.com/YMFE/yapi.git vendors <br></code></pre></td></tr></table></figure><p>下载完成后在 <code>yapi</code> 下产生 <code>vendors</code> 文件夹，</p><p><strong>在 <code>yapi</code> 文件夹下创建配置文件，可以通过拷贝 <code>config_example.json</code> 更改文件名于为 <code>config.json</code> 文件内容</strong></p><p><strong>同时删除 <code>vendors</code> 文件夹下的 <code>package-lock.json</code></strong></p><p>config的参考</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs sh">&#123;<br>  <span class="hljs-string">&quot;port&quot;</span>: <span class="hljs-string">&quot;3000&quot;</span>,<br>  <span class="hljs-string">&quot;adminAccount&quot;</span>: <span class="hljs-string">&quot;admin@admin.com&quot;</span>,<br>  <span class="hljs-string">&quot;timeout&quot;</span>:120000,<br>  <span class="hljs-string">&quot;db&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;servername&quot;</span>: <span class="hljs-string">&quot;127.0.0.1&quot;</span>,<br>    <span class="hljs-string">&quot;DATABASE&quot;</span>: <span class="hljs-string">&quot;yapi&quot;</span>,<br>    <span class="hljs-string">&quot;port&quot;</span>: 27017<br>  &#125;,<br>  <span class="hljs-string">&quot;mail&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;enable&quot;</span>: <span class="hljs-literal">false</span>,<br>    <span class="hljs-string">&quot;host&quot;</span>: <span class="hljs-string">&quot;smtp.163.com&quot;</span>,<br>    <span class="hljs-string">&quot;port&quot;</span>: 465,<br>    <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-string">&quot;***@163.com&quot;</span>,<br>    <span class="hljs-string">&quot;auth&quot;</span>: &#123;<br>      <span class="hljs-string">&quot;user&quot;</span>: <span class="hljs-string">&quot;***@163.com&quot;</span>,<br>      <span class="hljs-string">&quot;pass&quot;</span>: <span class="hljs-string">&quot;*****&quot;</span><br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>参考 shell 命令为</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">cp vendors/config_example.json ./config.json // ⚠️  复制完成后把内容修改为 config.json<br><span class="hljs-built_in">cd</span> vendors <br>rm package-lock.json // ⚠️ 一定要删除 package-lock.json <br></code></pre></td></tr></table></figure><p>接下来安装依赖，进入 <code>vendors</code> 文件夹，执行</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install --production --registry https://registry.npm.taobao.org <br></code></pre></td></tr></table></figure><p>此时可能会出现报错如 —— 依赖冲突、推荐你使用 --force or --legacy-peer-deps：</p><p>此时我是使用 --force 解决，即：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install --force --production --registry https://registry.npm.taobao.org<br></code></pre></td></tr></table></figure><p>--force 网上的解释是：<a href="https://www.coder.work/article/7517082">基于最后下载的依赖项，并将覆盖任何以前下载的依赖项</a></p><p>最后运行</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm run install-server <br>node server/app.js <br></code></pre></td></tr></table></figure><h2 id="运行">运行</h2><p>但是使用 <code>node</code> 的启动，关闭cmd之后就会停止服务，这里的解决办法是使用 <a href="https://pm2.io/">pm2</a></p><p><code>pm2</code> 的操作命令如下 （在 <code>vendors\server</code> 文件夹下运行）</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install -g pm2<br>pm2 start app.js        // 启动<br>pm2 start app.js -i max //启动 使用所有CPU核心的集群<br>pm2 stop app.js         // 停止<br>pm2 stop all            // 停止所有<br>pm2 restart app.js      // 重启<br>pm2 restart all         // 重启所有<br>pm2 delete  app.js      // 关闭<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>项目</tag>
      
      <tag>问题记录</tag>
      
      <tag>YApi</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DroidEvolver -- Self-Evolving Android Malware Detection System</title>
    <link href="/2021/11/16/DroidEvolver/"/>
    <url>/2021/11/16/DroidEvolver/</url>
    
    <content type="html"><![CDATA[<blockquote><p>原文链接：https://ieeexplore.ieee.org/document/8806731?denied=</p><p>​ https://ieeexplore.ieee.org/xpl/conhome/8790377/proceeding</p><p>发表会议： 2019 年 IEEE 欧洲安全和隐私研讨会 （EuroS&amp;P）</p></blockquote><h2 id="摘要">摘要</h2><p>​ 鉴于 <strong>Android 框架的频繁变化和 Android 恶意软件的不断发展</strong>，随着时间的推移，以有效且可扩展的方式检测恶意软件是具有挑战性的。</p><p>​ 为了应对这一挑战，我们提出了<strong>DrodEvolver</strong>，这是一个Android恶意软件检测系统，可以在恶意软件检测过程中自动和持续地更新自己，而无需任何人参与。虽然大多数现有的恶意软件检测系统可以通过对带有真实标签的新应用程序进行再训练来更新，但 <strong>DroidEvolver 既不需要再训练，也不需要真实标签来更新自己</strong>，这主要是因为 DroidEvolver 使用<strong>具有不断发展的特征集和伪标签的在线学习技术进行必要和轻量级的更新</strong>。在六年内开发的 33,294 个良性应用程序和 34,722 个恶意应用程序的数据集上评估了 DroidEvolver 的检测表现。</p><p>​ 使用 2011 年的6,286个应用程序作为初始训练集，DroidEvolver 实现了高检测 F-score（95.27%），对于57,539个新出现的应用进行分类，未来五年平均每年仅下降1.06%。请注意，此类新应用程序可以使用新技术和新的 API，在 2011 年应用启动时，DroidEvolver 不知道这些技术和 API。与目前最先进的恶意软件检测系统 MamaDroid 相比，DroidEvolver的 F-score 平均高2.19 倍（第五年高10.21倍），DroidEvolver 在恶意软件检测中的效率比 MamaDroid 高 28.58 倍，DroidEvolver 也显示对典型的代码混淆技术强健。</p><h2 id="介绍">1、介绍</h2><p>​ <strong>Android 应用程序和 Android 框架都随着时间的推移不断演变，原因多种多样，如特征增强和 bug 修复</strong>。因此，构建 Android 恶意软件检测系统变得越来越困难，这些系统经过旧的 Android 应用程序训练，在操作一段时间后能够有效且可扩展地检测新应用程序中的恶意软件。现有的Android检测系统的快速老化引起了业界和学术界的极大关注。在 BlaixHat 2016 中指出，百度开发的恶意软件检测系统的召回率在六个月内下降了7.6%。在研究文献中，最近通过 API 抽象使恶意软件检测适应 API 更改，但是，恶意软件检测的老化问题尚未完全解决。</p><p>​ 为了使恶意软件检测准确，<strong>大多数恶意软件检测系统需要及时和重复地使用新应用程序进行再训练</strong>。然而，这种解决办法面临若干挑战。</p><ul><li>首先，<strong>很难确定何时重新训练恶意软件检测系统</strong>，如果系统再训练过于频繁，则会导致资源浪费，而不提供新信息来丰富检测系统，否则，检测系统无法及时捕获某些新的恶意软件。</li><li>其次，<strong>再训练过程需要对所有经过处理的新应用程序进行手动标记</strong>，这受制于可用资源。手动标签的高成本通常会导致再训练周期较长，因此，检测表现会受到影响。</li><li>最后，大多数现有的恶意软件检测系统都进行了累积数据集的重新训练，包括原始训练数据集和新标记的应用程序。这种<strong>再训练过程成本高昂且无法扩展</strong>，尤其是在新应用数量随着时间而快速增长的情况下。</li></ul><p>​ 为了应对这些挑战，我们提出了一种名为 DroidEvolver 的新型自我进化的 Android 恶意软件检测系统，通过对其具有不断发展的特征集的检测模型进行必要的更新，使恶意软件检测随着时间的推移准确无误。DroidEvolver 维护着一组使用各种在线学习算法使用标记应用程序初始化的不同检测模型的模型池。维护模型池的原因是，不同的检测模型不太可能以相同的速度老化恶意软件检测，即使它们是用相同的数据集初始化的。在检测阶段，在”年轻“检测模型中进行加权投票，根据其 Android API 调用对每个应用程序进行分类。<strong>DroidEvolver 提取 Android API 调用作为检测特征</strong>，因为它们自然而然地反映了 Android 框架和应用程序的演变，并且它们可以轻松地从字节代码中提取，以便高效检测恶意软件。</p><p>​ <strong>检测应用程序的“年轻”模型根据<em>聚文化指示器</em>（JI） 确定</strong>，该指标是根据检测到的应用程序与检测模型分类为同一预测标签的一批应用程序之间的相似性来计算的。如果检测模型因检测到的应用程序而老化，DroidEvolver 会使用检测到的应用程序及其由模型池生成的分类结果（即伪标签）更新该模型。DroidEvolver还更新其特征集，以适应从应用程序中发现的 API 更改。</p><p>​ <strong>DroidEvolver使用 JI 来确定何时更新其特征集和每个检测模型</strong>。可以计算每个检测模型和检测到的每个新应用程序的 JI。如果 JI 属于一定范围，则相应的检测模型视为<em>老化模型。</em>如果模型池中的任何模型老化以检测此应用程序，则检测到的应用程序将识别为<em>漂移</em>应用程序。老化模型对漂移应用程序进行分类有局限性，其中可能包括新的 API 调用或新的 API 使用模式。因此，一旦识别漂移应用程序，DroidEvolver 将更新其特征集和所有老化模型。</p><p>​ 在恶意软件检测中更新其模型池时，<strong>DroidEvolver 不需要任何经过处理的应用程序的真实标签</strong>。这使得不必在DroidEvolver 初始化后对任何应用程序再进行手动标记，从而减少了DroidEvolver的资源和成本限制。在识别漂移应用程序的情况下，<strong>DroidEvolver 会为漂移应用程序生成一个伪标签，并在进入下一个应用程序之前根据漂移应用程序及其伪标签更新所有老化模型</strong>。如果当前应用程序不是漂移应用程序（因此没有识别老化模型），则模型池中的所有模型都有助于分类结果，并且不执行模型更新。</p><p>​ 随着时间的推移，<strong>DroidEvolver对于恶意软件检测非常有效</strong>。初始化后，它不需要定期对累积数据集进行任何再训练；相反，每当识别和处理单个漂移应用程序时，它就会高效演变，除非在这种情况下所有模型都在老化。为此，模型池中的所有检测模型都使用在线学习算法进行初始化，该算法可以通过流式传输数据执行增量学习。与批量学习算法相比，在线学习算法更高效、更可扩展，<strong>因为它们不仅避免了初始阶段原始训练数据集的批量处理，还避免了检测阶段累积数据集的定期再训练</strong>。虽然现有的在线学习算法仅与标记数据配合使用，但 DroidEvolver 使它们与检测阶段与伪标签相关的应用程序配合使用。与现有的在线学习方法不同，DroidEvolver 仅针对每个漂移应用程序更新每个应用程序的老化模型，从而更新每个应用的检测模型。在更新过程中，DroidEvolver 不需要任何真实标签与漂移应用程序相关联。从这个意义上说，DroidEvolver 比现有的基于在线学习的方法更实用。因此，在必要时，老化模型会迅速被重新确定。这进一步促进了DroidEvolver的效率。</p><p>​ DroidEvolver 通过一系列数据集进行严格评估，包括 2011 年至 2016 年 34,722 个恶意应用程序和 33,294 个良性应用程序。DroidEvolver的功效和效率与 MamaDroid 相比（MamaDroid 是一种最先进的恶意软件检测系统），可抵御 API 随时间的变化。在DroidEvolver 和 MamaDroid 在同一时期开发的相同应用中接受训练和测试的情况下，DroidEvolver 显著优于 MamaDroid ，在我们的实验中，F-score 提高了 15.80%，精度提高了 12.97%，召回率平均提高了 17.57%。在一到五年内对比训练套数较新的测试组进行评估时，DroidEvolver 的平均 F-score 分别为92.32%、89.30%、87.17%、87.46% 和 89.97%。相比之下，在相应情况下，MamaDroid 的平均 F-score 分别为68.01%、56.09%、45.88%、32.85% 和 8.81%。随着时间的推移，DroidEvolver 的整体 F-score 比 MamaDroid 的平均值高出 2.11 倍。五年来，DroidEvolver的 F-score 平均每年下降1.06%，而MamaDroid 在相同情况下每年平均下降13.52%。此外，如果只有少量带有真实标签的数据更新了F-score，DroidEvolver 将其 F-score 保持在较高水平，而在这种情况下，MamaDroid 的 F-score 每年都会下降。</p><p>​ 然后，我们评估DroidEvolver的效率，并将其与 MamaDroid 进行比较。DroidEvolver 的初始化需要线性时间，随着原始训练数据集从 10，000 个应用程序增加到 50，000 个应用程序，线性时间从 3s 到 27s 不等，而 MamaDroid 需要从 26s 到 1,207s 不等的非线性时间。在检测阶段，DroidEvolver平均需要 1.37s 才能处理未知应用程序，而 MamaDroid 在这种情况下平均需要 39.15s。</p><p>​ 我们还分析随着时间的推移在恶意软件检测过程中识别的老化模型和漂移应用程序。DroidEvolver 将 11.23% 的新应用识别为漂移，而每个检测模型均显示老化迹象，平均对大约 30.13% 的漂移应用进行分类。这些百分比在以后的应用开发后进行评估时保持稳定。此外，超过 50.00% 的检测模型被确定为老化，用于对 49.08% 的漂移应用进行分类。这些漂移应用程序是错误分类的主要来源，而老化模型的更新使DroidEvolver在恶意软件检测中延缓老化。</p><p><strong>本文的贡献主要如下：</strong></p><ul><li>我们提出了一种新的自我进化和高效的Android恶意软件检测系统 DroidEvolver。DroidEvolver 不仅在与训练应用程序同时开发的应用程序上，而且在使用新技术和新 API 训练应用程序后开发的新应用程序上，在恶意软件检测方面都是准确的。</li><li>DroidEvolver是有效的，因为DrodEvolver利用在线学习算法更新其老化模型从个别漂移应用程序在恶意软件检测，而不是定期从一批累积应用程序集合的再训练。与最先进的恶意软件检测系统 MAMADROID 相比，DroidEvolver在我们的实验中实现了更高的精度和更高的效率。</li></ul><p><strong>其余文件的架构如下</strong></p><ul><li>第二节详细说明了 DroidEvolver 的系统设计</li><li>第三节介绍了实验中使用的实验设置和参数调谐</li><li>第四节从不同方面评价 DroidEvolver，分析实验结果并讨论其局限性</li><li>第五节总结了相关工作</li><li>第六节总结了论文</li></ul><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu1-p16-xu-small.gif" alt="图1：DroidEvolver架构"></p><h2 id="droidevolver设计">2、DroidEvolver设计</h2><p>​ DroidEvolver 的结构1如图1所示。 DroidEvolver 由两个阶段组成，包括<em>初始化阶段</em>和<em>检测阶段</em>。</p><ul><li>在<strong>初始化阶段</strong>，DroidEvolver 将一组已知应用程序作为输入，这些应用程序与真实标签（即"恶意"和"良性"）相关联，并输出一组特征和一组检测模型，这些特征和模型被传输到检测阶段</li><li>在<strong>检测阶段</strong>，DroidEvolver 将每个真实标签未知的应用程序作为输入，并为未知应用输出预测标签</li></ul><p>​ DroidEvolver 的初始化阶段由四个模块组成，包括<em>预处理器</em>、<em>特征提取</em>、<em>矢量生成</em>和<em>模型池结构</em>。</p><p>​ 对于输入中的每一个已知应用程序，预处理器应用 <strong>apktool</strong> 来分解其 apk 文件并获取其拆解的 <strong>dex 字形码</strong>，其中包括本应用程序中使用的 API 调用。</p><p>​ 然后，特征提取模块用于提取所有 Android API，并将每个应用程序的 Android API 二进制存在记录为应用程序的检测特征。<em>初始特征集</em>（即总命令集）是通过结合输入中所有应用程序的检测特征构建的。特征空间由 1 比 1 映射构建，从初始特征集的所有特征到特征空间的尺寸。</p><p>​ 在矢量生成模块中，DroidEvolver 通过将所有检测特征的应用程序映射到特征空间，从所有检测模型的每个应用程序生成一个特征向量，<strong>其中初始特征集中的每个被检测到的特征被映射到组件1</strong>，而其他组件设置为0。</p><p>​ 通过输入中所有应用产生的特征向量，模型池构建模块构建了一个<em>初始模型池</em>，<strong>该模型池由一组检测模型组成</strong>。每个检测模型都使用不同的在线学习算法进行初始化，该算法根据其特征向量和真实标签处理所有输入应用程序。</p><p>​ 在初始化阶段结束时， DroidEvolver 将初始特征集和初始模型池传输到检测阶段。<strong>模型池中的每个检测模型都与<em>一个特征集指示器</em>相关联</strong>，该指示指示器模型可以处理的特征数量。<strong>所有特征集指标均初始化为初始特征集的大小，并可能在检测阶段增加到更大的值</strong>。</p><p>​ <strong>在检测阶段，DroidEvolver 将每个未知应用程序分类为恶意或良性应用，并对特征集和检测模型执行必要的更新</strong>。检测阶段的前三个模块与初始阶段的模块相似，但 (i) 特征集被动态更新以包含<strong>新特征</strong>，(ii) 其序号小于检测模型的特征集（<strong>上一代检测模型所使用的特征集</strong>）中的所有特征的 1 比 1 映射为每个检测模型构建一个特征向量，(iii) DroidEvolver 将应用程序的检测特征映射到检测模型（<strong>这一代所要使用的特征集</strong>）的特征空间，从每个检测模型的每个应用程序生成一个特征向量。</p><p>​ 在特征提取模块中， DroidEvolver 根据现有的Android API家族提取Android API，包括 Android、java、javax、junit、apach、json、dom和xml。虽然 API 包的数量从 API 级别 1 的 96 个（2008 年 10 月发布的 Android 版本 1.0）大幅增加到 API 级别 27 的 196 个（2017 年 11 月发布的 Android 版本 8.1），但 <strong>Android API 家族的名称随着时间的推移保持不变</strong>。在其检测阶段，只要新 API 调用的 API 系列保持不变， DroidEvolver 不会错过由 Android 框架演变引起的任何新的 Android API 调用。</p><p>​ 检测阶段的最后一个模块是<strong>分类和演化</strong>。在此模块中，DroidEvolver 为输入中给出的每个未知应用程序生成分类结果（恶意或良性）。如果模型池中的某些检测模型在检测未知应用程序时老化，DroidEvolver 会<strong>根据包括未知应用程序中使用的所有新的 Android API 调用</strong>，并将每个老化模型的特征集指示器<strong>更新</strong>为新的特征集的大小，从而逐步更新其特征集（不更改任何现有特征的序号）。此外，<strong>DroidEvolver 根据分类结果和更新的特征向量，通过从未知应用程序中学习来更新每个老化模型</strong>。</p><p>​ 本节的其余部分阐明了模型池在初始阶段的构建方式，以及如何在检测阶段实现分类和演变。</p><h3 id="模型池建设">2.1、模型池建设</h3><p>​ 由于在初始化阶段有一组已知应用程序及其相关的真实标签，DroidEvolver 构建了一个模型池，其中<strong>具有一组在线学习算法</strong>，而不是用于恶意软件检测的任何单一检测模型。单个检测模型能力有限，可能不一定提供提供准确的检测结。模型池可以帮助检测和降低任何单一检测模型的偏差，并在检测阶段生成更可靠的检测结果。</p><p>​ 模型池中的每个检测模型都使用不同的在线学习算法构建，该算法一次处理一个应用程序。在线学习的复杂度与输入中的应用程序数量是成正比的，这与需要同时处理一组应用程序的批次学习不同。下面给出了DroidEvolver 中在线学习算法的常见过程：</p><p>​ 让 DroidEvolver 的输入成为 <em>N</em> 已知应用程序的总命令集。让 <span class="math inline">\(x_t\)</span> 是输入中 <em>t-th</em> 应用程序的<span class="math inline">\(d\)</span> 维真实值特征向量，其中 <span class="math inline">\(d\)</span> 是源自特征提取模块中的输入的初始特征集的大小。让 <span class="math inline">\(y_t\)</span> 是输入中 第 <span class="math inline">\(t\)</span> 应用程序的真实标签，其中 <span class="math inline">\(y_t=+1\)</span> 表示 ”恶意“ 和 <span class="math inline">\(y_t = +1\)</span> 表示 ”良性“。每个在线学习算法的输入是 <span class="math inline">\((x_t， y_t), t = 1,..., N\)</span> ，每个在线学习算法都使用一个检测模型，该模型由<em>d</em>维权重向量表示<span class="math inline">\(w_t\)</span>，处理 <span class="math inline">\((x_t， y_t)，1 ≤ t ≤ N\)</span> 权重向量由初始特征集中所有特征的权重组成。</p><p>​ 在每一步<em>t</em>，每个在线学习算法过程 <span class="math inline">\(x_t\)</span> 并生成预测标签 <span class="math inline">\(\hat{y_t} = sgn(w_t,x_t)\)</span>， 其中<span class="math inline">\(sgn\)</span>是一个函数， 将任何非负值映射到 +1， 并将任何负值映射到 -1。损失值 <span class="math inline">\(l_t(y_t，\hat{y_t})\)</span> 在步骤 <span class="math inline">\(t\)</span> 然后从真实标签计算 <span class="math inline">\(y_t\)</span> 和预测标签 <span class="math inline">\(\hat{y_t}\)</span> 每个在线学习算法都对如何计算损失值实施不同的策略<span class="math inline">\(l_t\)</span> 并将其权重向量 <span class="math inline">\(w_t\)</span> 更新为 <span class="math inline">\(w_{t+1}\)</span>。</p><p>​ 在 DroidEvolver 中，每个探测模型都定义了超平面 <span class="math inline">\(\{x∈\mathbb{R}^d|w_t ⋅ x = 0\}\)</span>，其中 <span class="math inline">\(w_t\)</span> 是部分在线学习算法生成的检测模型的权重向量。具有权重向量的检测模型 <span class="math inline">\(w_t\)</span> 和 对应用程序进行分类的特征向量与模型超平面的距离 <span class="math inline">\(x_t\)</span>相乘：如果距离<span class="math inline">\(w_t•x_t\)</span>非负数，预测标签为”恶意“：否则，预测标签是”良性的“。绝对值 <span class="math inline">\(w_t•x_t\)</span> 被称为模型的<strong>预测分数<span class="math inline">\(xt\)</span></strong></p><p>​ DroidEvolver 构建了由五个线性在线学习算法组成的模型池，包括<strong>Passive Aggressive（PA） 、在线梯度下降（OGD）、权重向量的自适应规范化（AROW）、规范化双平均（RDA） 和自适应向前向后拆分（Ada-FOBOS）</strong>。这些算法涵盖了主要的在线学习算法类别，包括一阶在线学习（包括PA和OGD），二阶在线学习（包括AROW），以及具有规范化的在线学习（包括RDA和Ada-FOBOS）。</p><p>​ 一阶在线学习算法旨在仅使用一阶梯度信息优化目标特征。一阶算法的优点是其计算复杂性与输入大小是线性的。与仅利用梯度一阶衍生信息进行在线优化任务的一阶在线学习算法不同，二阶在线学习算法利用一阶和二阶信息来加速优化融合。但是，二阶在线学习算法在处理高维数据时往往具有很高的计算复杂性。这一挑战可以通过具有规范化的在线学习算法来应对，该算法旨在利用真实世界高维数据的稀缺性属性。此外，<strong>每个类别中选定的算法在更新策略、学习速度、优化方法和损失特征方面都有所不同</strong>，这使得当 DroidEvolver 应用于恶意软件检测时，各种检测模型在模型池中的老化方式会有所不同。下面解释了选定的在线学习算法的更新程序。</p><h4 id="passive-aggressivepa">Passive Aggressive（PA）</h4><p>​ PA 以多个步骤逐步构建其检测模型。在每一步 <span class="math inline">\(t\)</span> 中，PA 都会接受样本 <span class="math inline">\(x_t\)</span> 使用当前模型<span class="math inline">\(w_t\)</span>，预测其标签 <span class="math inline">\(\hat{y}_t\)</span> ；然后，它收到 <span class="math inline">\(x_t\)</span> 真正的标签 <span class="math inline">\(y_t\)</span> 并计算铰链损失<span class="math inline">\(l_t = max\{0, 1 - y_t(w_t * x_t)\}\)</span>。最后，PA 将学习率设定为 <span class="math inline">\(l_t = max\{0, 1 - y_t(w_t * x_t)\}\)</span> 并更新 <span class="math inline">\(w_{t+1} = wt + τ_ty_tx_t\)</span>。</p><p>​ 在每一步中，如果铰链损失为 0（即，<span class="math inline">\(w_{t+1} = w_t, 如果l_t= 0\)</span>），模型更新就是消极的。否则，PA 更新 <span class="math inline">\(w_{t+1}\)</span> 就是积极。PA 确保更新 <span class="math inline">\(w_{t+1}\)</span> 应保持接近 <span class="math inline">\(w_t\)</span> 并且每个传入的样本都应通过更新后的模型正确分类。</p><h4 id="在线梯度下降-ogd">在线梯度下降 （OGD）</h4><p>​ OGD 具有与 PA 类似的更新策略，但 OGD 采用预先定义的学习率计划，而 PA 则在每一步中选择最佳学习率。在每一步 <span class="math inline">\(t\)</span> 中，OGD 都会收到样本 <span class="math inline">\(x_t\)</span> 使用当前模型<span class="math inline">\(w_t\)</span>，预测其标签 <span class="math inline">\(\hat{y}_t\)</span> ；然后，它收到 <span class="math inline">\(x_t\)</span> 真正的标签 <span class="math inline">\(y_t\)</span> 并计算铰链损失<span class="math inline">\(l_t = max\{0, 1 - y_t(w_t * x_t)\}\)</span>。之后，OGD 更新 <span class="math inline">\(w_{t+1}= ∏_S(w_t-η_t∇l_t(w_t))\)</span>， 其中 <span class="math inline">\(η_t\)</span> 是预先定义的学习率， <span class="math inline">\(S\)</span> 是一个凸集且初始化为 <span class="math inline">\(t = 0\)</span>， 且 <span class="math inline">\(∏_S\)</span> 是将更新的模型限制在可行域中的投影函数。具体地说，如果<span class="math inline">\(w_t-η_t∇l_t(w_t) \notin S\)</span>，<span class="math inline">\(∏_S\)</span>将 <span class="math inline">\(w_t-η_t∇l_t(w_t)\)</span> 投影到 <span class="math inline">\(S\)</span> 中距离 <span class="math inline">\(w_t-η_t∇l_t(w_t)\)</span> 最近的向量，这个被投影的向量即为 <span class="math inline">\(w_{t+1}\)</span></p><h4 id="权重向量的自适应规范化arow">权重向量的自适应规范化（AROW）</h4><p>​ AROW 将不同特征的出现频率考虑到模型更新中。<strong>在 AROW 中，常见的特征会收到更多的更新，并且与较少的特征相比，常见的特征估计更准确。</strong></p><p>​ AROW 在特征权重上保持高斯分布（均值为 <span class="math inline">\(μ\)</span> 和方差为 <span class="math inline">\(Σ\)</span> ，即 $ w N(μ, Σ)$ ）。ROW初始化 <span class="math inline">\(μ_0 = 0\)</span> 和 <span class="math inline">\(Σ_0= I, 即单位矩阵\)</span>。给定 <span class="math inline">\(x_t\)</span> 在每一步 <span class="math inline">\(t\)</span> 中，AROW 计算边距 <span class="math inline">\(mt = μ_{t-1} • x_t\)</span>和 置信度 <span class="math inline">\(v_t = x_t ^⊤ ∑_{t-1}x_t\)</span>。</p><p>​ 然后，它收到 <span class="math inline">\(x_t\)</span> 真正的标签 <span class="math inline">\(y_t\)</span> ，AROW 损失 <span class="math inline">\(l_t = 1\ if\ sgn(m_t) ≠ y_t\)</span>。 $$ \mu _t = {\mu _{t - 1}} + \frac{{\max (0,1 - {y_t}{x_t}^{^ \top }{\mu _{t - 1}})}}{{{x_t}^{^ \top }{\Sigma _{t - 1}}{x_t} + r}}{\Sigma _{t - 1}}{y_{{t^X}t}}$$  ​ <span class="math inline">\(r\)</span> 是由参数调谐设置的输入参数</p><p>​ 如果 <span class="math inline">\(μt≠μ_{t+1}\)</span>， AROW 更新方差 <span class="math inline">\(\Sigma_t\)</span> ： $$ \Sigma _t = {\Sigma _{t - 1}} - \frac{{{\Sigma _{t - 1}}{x_t}{x_t}^{^ \top }{\Sigma _{t - 1}}}}{{{x_t}^{^ \top }{\Sigma _{t - 1}}{x_t} + r}}$$  ​ 之后，AROW 输出更新的平均值 <span class="math inline">\(μ_t\)</span> 和 方差 <span class="math inline">\(∑_t\)</span>，然后用于计算更新的权重向量。</p><h4 id="正规化双平均值rda">正规化双平均值（RDA）</h4><p>​ RDA 通过解决每个样本的最小化问题来调整其参数。在每一步 <span class="math inline">\(t\)</span> 中，RDA 计算子梯度 <span class="math inline">\(g_t∈∂f_t(w_t)\)</span>，其中 <span class="math inline">\(f_t\)</span> 是步骤 <span class="math inline">\(t\)</span> 的代价函数。子梯度 <span class="math inline">\(g_t\)</span> 用于计算平均子梯度。然后，RDA 会更新平均子梯度：<span class="math inline">\(\bar{g_t}=\frac{t-1}{t} + \frac{\bar{g_t}}{t}\)</span> 。 Rda 通过解决最小化问题更新当前的权重向量： $$ \begin{equation*}{w_{t + 1}} = \arg \mathop {\min }\limits_w \left\{ {{{\bar g}_t}^{^ \top }w + \Psi (w) + \frac{{{\beta _t}}}{t}h(w)} \right\}\end{equation*}$$  ​ 其中 <span class="math inline">\(β_t\)</span> 是一个非负序列，$Ψ(w) $ 是原始的稀疏诱导规范 （即，<span class="math inline">\(Ψ(w) = λ‖w‖_1\)</span>）<span class="math inline">\(h(w)\)</span> 是辅助强凸函数（即<span class="math inline">\(h(w)= \frac{1}{2}∥w∥^2\)</span>），<span class="math inline">\(\bar{g_t}\)</span> 是所有以前迭代的平均子梯度和 （即$ {g} =  * _{t}^{τ=1}∇l_τ(w_τ))$）</p><h4 id="自适应向前向后拆分ada-fobos">自适应向前向后拆分（Ada-FOBOS）</h4><p>​ RDA 的一个主要问题是，基础数据分布的几何信息可能无法被辅助强凸函数<span class="math inline">\(h(w)\)</span>充分利用。为了应对这一挑战，Ada-FOBOS 提出了一个数据驱动的<strong>自适应规范化</strong><span class="math inline">\(h(w)\)</span>： $$ \begin{equation*}{h_t}(w) = \frac{1}{2}{w^{^ \top }}{H_t}w\end{equation*}$$  其中 <span class="math inline">\(H_t\)</span> 是对角矩阵。</p><p>​ 更新过程描述如下：在每一步 <span class="math inline">\(t\)</span>，Ada-FOBOS 接收 <span class="math inline">\(x_t\)</span> 并预测其标签 <span class="math inline">\(\hat{y}_t\)</span>。 然后，它遭受损失 <span class="math inline">\(l_t\)</span> 并计算相对于 <span class="math inline">\(w_t\)</span> 的梯度 <span class="math inline">\(g_t\)</span>。 之后，它更新 <span class="math inline">\(h_t(w)\)</span> 的对角矩阵 <span class="math inline">\(H_t\)</span>： $$ \begin{equation*}{H_t} = \delta + diag\left(\sum\limits_{i = 1}^t {{g_i}} {g_i}^{^ \top }\right)\end{equation*}$$  其中δ是确保自适应加权矩阵的正确定属性的参数。最后，Ada-FOBOS 更新权重向量 <span class="math inline">\(w_t+1 = w_t − \frac{τg_t}{H_t}\)</span>，其中 <span class="math inline">\(τ\)</span> 是学习率。</p><p>​ 在处理了输入中所有的应用程序后，DroidEvolver 输出了五个检测模型作为模型池，并将每个检测模型与一个特征集指示器关联在一起，该指示器初始化为初始特征集的大小。然后，DroidEvolver 将模型池传输到检测阶段进行分类和进化。</p><h3 id="分类和演变">2.2、分类和演变</h3><p>​ 在检测阶段，分类和演化模块对每个未知应用进行分类，并对其特征集和模型池进行必要的更新。该模块由三个步骤组成，包括<strong>漂移应用识别</strong>、<strong>分类和伪标签生成</strong>以及<strong>老化模型聚光化</strong>。</p><h4 id="漂移应用程序标识与何时演变">漂移应用程序标识与何时演变</h4><p>​ 使用旧应用程序进行训练的恶意软件检测模型在检测开发比训练数据较晚的新应用程序时通常会产生不令人满意的结果。这种现象被称为<strong>概念漂移</strong>。为了使恶意软件检测适应概念漂移，DroidEvolver 识别了与以前处理过的旧应用程序不同的漂移应用程序。对于每个漂移应用程序，DroidEvolver 可识别显示老化迹象的老化模型，以对漂移应用进行分类。漂移应用的出现表明有必要更新DrodEvolver的相应老化模型，以保持其在恶意软件检测中的有效性。</p><p>​ DroidEvolver 使用<strong>聚光化指示器</strong>（简称 JI）来确定未知应用程序在检测模型处理时是否漂移。简言之，JI 表示新应用程序与检测模型测量的一批应用程序之间的相似性。为了高效计算 JI 的新应用程序，DroidEvolver 使用<strong>App数组</strong> <span class="math inline">\(B = (b_1,...,b_k), size = K\)</span>存储已处理的应用程序子集的特征向量，其中 <span class="math inline">\(K (≤ N)\)</span>是 DroidEvolver 中的参数，<span class="math inline">\(b_t, (1≤ t ≤ K)\)</span> 是以前处理过的某些应用程序的特征向量。</p><p>​ 在检测阶段的开始，App数组中的 <span class="math inline">\(K\)</span> 中的App 是从初始阶段给出的输入中随机选择的。为了保持现有应用数组的更新，每当将新应用程序作为检测阶段的输入时，DroidEvolver 会随机选择 App数组中的一个特征向量，替换为 JI 计算新应用程序的特征向量。</p><p>​ 特别是，假设 DroidEvolver 已经完成了对第 <span class="math inline">\((i-1)\)</span> 个未知应用程序的检测，并收到了新的App <span class="math inline">\(A_i\)</span>。</p><p>​ <span class="math inline">\(x_i\)</span> ： <span class="math inline">\(A_i\)</span> 的特征向量</p><p>​ <span class="math inline">\(M_j\)</span>：是第j个检测模型（使用当前模型池）</p><p>​ <span class="math inline">\(B\)</span>：被<span class="math inline">\(A_j\)</span> 更新过的 App数组</p><p>​ <span class="math inline">\(σ\)</span>：指示函数，<span class="math inline">\(σ(true) = 1, σ(false) = 0\)</span></p><p>​ 对于模型 <span class="math inline">\(M_j\)</span> 检测 App <span class="math inline">\(A_i\)</span> 的聚光化指示器 JI 为： $$ \begin{equation*} {\xi _{ij}} = \begin{cases} {\frac{{\sum\limits_{{b_t} \in B} \sigma ({w_j}\cdot{x_i}. \geq {w_j}\cdot{b_t})}}{{\sum\limits_{{b_t} \in B} \sigma ({w_j}{b_t} \geq 0)}}}&{{\text{if}}\;{w_j}\cdot{x_i} \geq 0} \\ {\frac{{\sum\limits_{{b_t} \in B} \sigma ({w_j}.{x_i} < {w_j} \cdot {b_t})}}{{\sum\limits_{{b_t} \in B} \sigma ({w_j} \cdot {b_t} < 0)}}}&{{\text{else}}} \end{cases}\tag{1}\end{equation*}$$  ​ 在 <span class="math inline">\(ξij\)</span> 的定义中，<span class="math inline">\(M_j\)</span> 对 <span class="math inline">\(A_i\)</span> 的<strong>预测分数</strong>与 <span class="math inline">\(M_j\)</span> 对App数组中由 <span class="math inline">\(M_j\)</span> 分类到 <span class="math inline">\(A_i\)</span> 的预测标签的应用程序的预测分数进行比较。</p><p>​ 如果 <span class="math inline">\(M_j\)</span> 对 <span class="math inline">\(A_i\)</span> 的预测标签是恶意的（分别是良性的），<span class="math inline">\(M_j\)</span> 的 App 数组来说中的App， <span class="math inline">\(M_j\)</span> 对 <span class="math inline">\(A_i\)</span> 的预测分数在<span class="math inline">\((100•ξ_{ij}\%, 100•(1− ξ_{ij})\%)\)</span>之间，将被 <span class="math inline">\(M_j\)</span> 分类为“恶意”。</p><p>​ 如果 <span class="math inline">\(A_i\)</span> 的特征向量 <span class="math inline">\(x_i\)</span> 与应用程序缓冲区中包含的其他特征向量（即来自处理应用程序的异常值）相比，离 <span class="math inline">\(M_j\)</span> 的超平面太近或太远，则 <span class="math inline">\(A_i\)</span> 被识别为检测模型 <span class="math inline">\(M_j\)</span> 的漂移应用程序。 DroidEvolver 使用两个阈值 <span class="math inline">\(τ_0 ,τ_1(0 ≤ τ_0 ≤ τ_1 ≤ 1)\)</span>，根据 JI 值识别漂移应用程序。 如果<span class="math inline">\(τ_0 ≤ ξ_{ij} ≤ τ1\)</span>，则认为 <span class="math inline">\(ξ_{ij}\)</span> 有效； <strong>否则，<span class="math inline">\(ξ_{ij}\)</span> 无效，则将 <span class="math inline">\(M_j\)</span> 标记为检测 <span class="math inline">\(A_i\)</span> 的老化模型</strong>，其中 <span class="math inline">\(ξ_{ij} ≤ τ_0\)</span> 在初始化阶段被选择并在检测阶段被强制执行。 <strong>如果模型池中的任何检测模型是用于检测它的老化模型，则未知应用程序被识别为漂移应用程序</strong>。 每当识别出漂移应用程序时，DroidEvolver 都会对其特征集和模型池中的老化模型进行必要的更新。</p><h4 id="分类---伪标签生成-与-什么一起进化">分类 - 伪标签生成 与 什么一起进化</h4>​在检测阶段，DroidEvolver 通过加权投票生成每个未知应用程序的分类结果。如果输入应用程序 $A_j$ 不是漂移应用程序，加权投票由模型池中的所有检测模型使用执行   ${\textstyle \sum_{j=1}^{M}} {{w_j} \cdot {x_i}}$ 其中 $M$ 是模型池的大小，$w_j$ 是模型的权重向量 $M_j$ 在模型池中， $x_i$是$A_i$的特征向量，如果模型投票是非阴性的，被归类为"恶意"，否则，其分类结果为"良性"。<p>​ 如果<strong>输入应用程序被确定为漂移应用程序</strong>，则模型池中的检测模型执行加权投票，时不包括所有检测该应用已经老化的模型。然后，漂移应用程序的分类结果用作其伪标签，用于更新特征集和所有老化型号。在另一种情况下，所有模型都在老化或没有模型正在老化，DroidEvolver 在模型池中执行所有模型之间的加权投票，并跳过更新过程。</p><h4 id="老化模型聚化---如何进化">老化模型聚化 - 如何进化</h4><p>​ 模型池中漂移应用和老化模型的适当子集的识别表明，由于以下原因，应根据漂移应用对老化模型进行聚合，以便随着时间的推移进行可靠的恶意软件检测。首先，漂移应用程序与其他处理应用程序之间的差异可能由<strong>漂移应用程序中包含的新特征或新模式引起</strong>。因此，适应这些新特征非常重要。此外，<strong>老化模型的检测能力受到”老化“特征集和模型结构的限制</strong>，需要更新这些特征，以便将来进行准确的分类。</p><p>​ 在这种情况下，DroidEvolver <strong>首先更新其当前特征集</strong>，包括从漂移应用程序中提取的所有新特征。然后，<strong>DroidEvolver 通过学习漂移应用和相应的伪标签，单独更新每个老化模型的特征集指示器和模型结构</strong>。模型结构包括权重向量的维度（根据当前特征设置指标）和权重向量的值（根据处理应用程序中包含的特征）。</p><p>​ 让 <span class="math inline">\(y_i\)</span> 表示漂移应用程序的伪标签，<span class="math inline">\(W_j\)</span> 表示老化模型的权重向量，DroidEvolver 更新每个对于 <span class="math inline">\(A_j\)</span> 老化模型 <span class="math inline">\(M_j\)</span> 分为四个步骤：首先，DroidEvolver 使用 <span class="math inline">\(M_j\)</span> 计算 <span class="math inline">\(A_j\)</span> 的预测标签 $_t $ 。然后，它揭示了伪标签 <span class="math inline">\(y_i\)</span> 自 <span class="math inline">\(M_j\)</span> 并计算损失值。为 <span class="math inline">\(Mj\)</span> 根据损失函数 <span class="math inline">\(l_j\)</span> 之 <span class="math inline">\(M_j\)</span> 在线学习算法。</p><p>​ 第三，更新特征集指标 <span class="math inline">\(M_j\)</span> 是更新的特征集的大小，并更新后的特征集和更新的特征集指示器更新 <span class="math inline">\(A_j\)</span> 的特征向量根据。最后，它依赖于在线学习算法 <span class="math inline">\(M_j\)</span> 决定更新的时间和方式 <span class="math inline">\(M_j\)</span> 根据更新策略。</p><p>​ <strong>特征集和老化模型的必要更新使 DroidEvolver 能够适应 Android 应用程序和 Android 框架的变化</strong>。与现有的基于在线学习的方法不同，DroidEvolver 依靠模型池而不是单个检测模型来生成其检测结果。此外，DroidEvolver 不需要更新老化模型的漂移应用程序的真实标签。</p><h2 id="实验设置和参数调谐">3、实验设置和参数调谐</h2><p>在一系列实验中，对DroidEvolver 的表现进行了经验评估。本节详细介绍了实验设置和参数调整。</p><h3 id="数据收集">3.1、数据收集</h3><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu.t1-p16-xu-small.gif" alt="表1 - 近些年的数据集分布"></p><p>​ 我们在 2017 年 7 月从一个开放的 Android 应用程序收集项目收集了一组应用程序。我们数据集中应用的标签是由我们在 2017 年 8 月从 VirusTotal获得的报告确定的，该报告是一个具有 63 个扫描仪的服务。</p><ul><li>如果应用程序<strong>没有收到来自所有扫描仪的警报</strong>，则会标记为良性。</li><li>另一方面，如果应用程序<strong>收到来自 63 台扫描仪的至少 15 个警报（即大约 24% 的扫描仪发出警报）</strong>，则该应用程序会被标记为恶意。</li></ul><p>​ 我们标记应用程序的方式与之前关于恶意软件检测的研究一致。例如，Arp 等人将应用程序标记为恶意，如果它收到来自至少 20% 的扫描仪的警报。生成的良性数据集由 33,294 个应用程序组成，恶意数据集包含 34,722 个应用程序。每个应用程序的时间由应用程序的 apk 文件打包的时间决定，该文件包含在 apk 文件的 dex 文件中。收集的数据集中的应用程序日期涵盖 2011 年至 2016 年。如表一所示，每个数据集都包含几乎平衡的良性应用程序（42.1%-50.5%）和恶意应用程序。</p><h3 id="指标和测量">3.2、指标和测量</h3><p>The performance of DroidEvolver is assessed using standard F-measure, i.e.: $$ \begin{equation*}{\text{F}} - {\text{measure}} = 2 \cdot \frac{{{\text{Precision}} \cdot \operatorname{Re} {\text{call}}}}{{{\text{Precision}} + \operatorname{Re} {\text{call}}}}\end{equation*}$$  其中 <span class="math inline">\(Precision = TP/(TP+FP),\ Recall= TP/(TP+FN)\)</span></p><p>TP 表示正确检测的恶意应用程序数量</p><p>FP 表示被错误地检测为恶意的良性应用程序数量</p><p>FN 表示被错误地检测为良性的恶意应用程序数量</p><p>在下面描述的两种情况下检测 DroidEvolver 的表现</p><p><strong>同一时间段内的表现</strong>。为了避免过度拟合，选择DroidEvolver 的参数，以便DroidEvolver 在训练集初始化后在验证集上实现最佳表现：然后，DroidEvolver 的表现在测试集上进行评估，其中训练集、验证集和测试集是在同一时间段内开发的不同应用程序集，没有重叠。</p><p>​ 我们的实验有六个时间段，包括 2011 年、2011-2012 年、2011-2013 年、2011-2014 年、2011-2015 年和 2011-2016 年。在每个时间段内，应用程序都会随机洗牌，并分为五个大小相等的子集。我们随机选择三个子集作为训练集，一个子集作为验证集，其余子集作为测试集。</p><p><a href="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu2-p16-xu-large.gif"><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu2-p16-xu-small.gif" alt="Fig. 2: - Detection F-measure under Different Thresholds"></a></p><h3 id="参数选择">3.3、参数选择</h3><p>​ 对于每个时间段，选择参数，以便 DroidEvolver 的表现在通过训练集初始化后，通过验证集进行优化。然后强制执行选定的参数，以检测测试集中的恶意软件（日期为相同或较晚的时间段）。在以下情况下，我们将显示参数调整在实验环境中的执行情况，我们称之为默认设置。在此设置中，2011 数据集用于形成训练集（6,286 个应用程序）和验证集（2,095 个应用程序）。</p><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu.t2-p16-xu-small.gif" alt="表二 - 同一时期检测的DroidEvolver 和 MAMADROID 表现"></p><h4 id="阈值调整">阈值调整</h4><p>​ 两个阈值：<span class="math inline">\(τ_0\)</span> 和 <span class="math inline">\(τ_1\)</span>，用于根据检测阶段的 JI 值识别漂移应用和老化模型。</p><p>​ 图2 显示了在默认设置中调整阈值对 DroidEvolver 表现的影响。图2说明，当 DroidEvolver 的 F-score 稳定时，<span class="math inline">\(τ_0\)</span> 从 0.1 增加到 0.3 ， <span class="math inline">\(τ_1\)</span> 从 0.6 增加到 0.8。当 $ τ_0 = 0.3, τ_1 = 0.7$，F -score 达到其最大值 96.33%，在验证集上达到最佳表现，DroidEvolver 选择 $ τ_0 = 0.3, τ_1 = 0.7$ 。</p><h4 id="app数组大小调整">App数组大小调整</h4><p>​ 回想一下，在分类和演化模块中使用了App数组，以便高效计算 JI。<strong>应用缓冲<span class="math inline">\(B\)</span>的<span class="math inline">\(K\)</span>大小会影响漂移应用程序的识别</strong>，从而影响 DrodEvolver 的检测 <span class="math inline">\(F -score\)</span> 以及处理所有未知应用程序所需的时间。</p><p>​ 图3 显示了 DroidEvolver 的 <span class="math inline">\(F - score\)</span> 以及不同 App数组大小下分类和演化模块中 2,095 个应用程序的处理时间，其中阈值设置为+0• 0.3和 +1= 0.7。当应用缓冲大小K从 10 增加到 10,000 时，DrodEvolver 的 F - score 从 91.45% 到 96.41% 不等， 表明 <strong>F-score 对 K 的变化不太敏感</strong>。另一方面，随着 <span class="math inline">\(K\)</span> 从10到10,000的变化，所有应用程序的处理时间从 200 显著增加到 4,759。为了平衡 F - score 和效率，<strong>DroidEvolver 在默认设置中选择 K = 500</strong>。</p><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu3-p16-xu-small.gif" alt="图 3： - App数组大小调谐"></p><h2 id="评价和分析">4、评价和分析</h2><p>​ 在本节中，使用表一中总结的数据集，在一系列实验中评估和分析 DroidEvolver 的表现。DroidEvolver 的表现与 MAMADROID 进行比较，MAMADROID 是一种最先进的恶意软件检测系统，能够适应 Android API 随时间的变化。MAMADROID 首先使用Soot 和 FlowDroid 从每个应用程序中提取 API 调用图；然后，它从 API 调用图中提取一组 API 调用序列，并抽象每个 API 调用在包模式下的包或在家族模式下对其家族。从抽象的 API 调用序列中，MAMADROID 通过评估抽象 API 调用之间所有转换的概率来构建马尔科夫链。然后，它根据其 Markov 链从每个应用程序中获取一个特征矢量，其中每个非零特征向量组件是马尔科夫链中的相应概率。MAMADROID 使用批量学习算法构建检测模型并检测未知应用的恶意软件。</p><p>​ 为了表现比较，我们使用其源代码实现了 MAMADROID，并在其包模式（始终优于家族模式）中操作它，其中批量学习分类算法是随机森林（有最佳表现）。我们在同一实验环境中评估了 DroidEvolver 和 MAMADROID。</p><h3 id="同一时间段内检测">4.1、同一时间段内检测</h3><p>​ 表二比较了DroidEvolver 和MAMADROID在F-score、精度和召回方面的表现。在每个实验中，DroidEvolver 和 MAMADROID 都使用相同的训练集进行初始化/训练，并使用相同的测试集进行评估。在所有实验中，DroidEvolver 机始终显著地超过MAMADROID，平均实现15.80%的 F-score，12.97%的精度和17.57%的召回率。通过从漂移应用中学习并适应新变化，DroidEvolver 平均使用 Android API 作为检测特征实现了 96.15% 的 F-score。</p><h3 id="随着时间推移检测">4.2、随着时间推移检测</h3><p>​ 我们的下一个和主要重点是 DroidEvolver 和MAMADROID的检测表现随着时间的推移，他们的检测模型训练与一组应用程序在一个时间段内开发，然后测试与另一组应用程序在以后的时间段开发。</p><p>​ 如图4所示，在所有实验中， DroidEvolver 的对于老化的表现都比MAMADROID获得显著优势。当 DroidEvolver 在测试组上评估比训练集新一到五年时， DroidEvolver 的平均 F-score 分别为92.32%、89.30%、87.17%、87.46%和89.97%。相比之下，在相应情况下，MAMADROID的平均F-score分别为68.01%、56.09%、45.88%、32.85%和8.81%。随着时间的推移， DroidEvolver 的整体 F-score 值比 MAMADROID 的平均值高出 2.11 倍。五年来， DroidEvolver 的 F-score 平均每年下降1.06%，而MAMADROID在相同情况下每年平均下降13.52%。</p><p>​ 图4还显示，在运行了两到三年之后， DroidEvolver 的 F-score 变得稳定。在其检测阶段，DroidEvolver 会自动从带有伪标签的漂移应用程序中学习，并更新其特征集和模型池。相比之下，MAMADROID 中的检测模型在训练后不会发生任何变化。与MAMADROID相比， DroidEvolver 的优势更为明显，在默认设置中，训练集相对较旧，体积较小，如图4a所示。</p><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu4-p16-xu-small.gif" alt="Fig. 4: - DroidEvolver 和 MAMADROID 的检测表现：a、b、c、d和e分别显示2011年、2011年、2012年、2011年和2011年以及2011年训练组的初始训练结果"></p><h3 id="模型更新的影响">4.3、模型更新的影响</h3><p>​ DroidEvolver 通过从没有真实标签的漂移应用程序中学习，在检测阶段执行必要的模型更新。尽管如此，<strong>如果某些应用程序有真实的标签，DroidEvolver 可以在此类应用程序上执行轻量级模型更新</strong>。</p><p>​ 在使用 2011 年训练集初始化后，DroidEvolver 和 MAMADROID 通过更新其模型，在恶意软件检测过程中，使用带有真实标签的随机选择漂移应用程序的固定百分比进行进一步测试，<strong>其中漂移应用程序平均占所有测试应用程序的 11.23%</strong>。如图5所示，DroidEvolver 在所有设置中都明显且始终优于MAMADROID。随着时间的推移，DroidEvolver 的整体 F -score 值比 MAMADROID 的平均值高出 1.44 倍。此外，如果使用真实标签的漂移应用程序更新 60% （或以上）， DroidEvolver 将其平均 F -score 值保持在 92% 以上。由于每年约有 11.23% 的测试应用程序被确定为漂移应用，因此，如果每年只有约 6.74% 的测试应用程序更新了真实标签，DroidEvolver 可以保持其检测表现处于高水平。从少量带有真实标签的应用程序中学习有助于 DroidEvolver 以更高的质量更新自身，并实现更好的检测表现。</p><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu6-p16-xu-small.gif" alt="图 6： - 默认设置中 DroidEvolver、一般的 DroidEvolver 解决方案和 MAMADROID 的检测表现"></p><p>​ 如图5中的白条所示，当带有真实标签的漂移应用百分比从0%增加到100%时，DroidEvolver 的平均 F-score 值略有不同，从90.51%到92.89%不等。此外，当百分比从 40% 增加到 100% 时，F-score 保持稳定。相比之下，MAMADROID 的平均 F-score 从 41.29% 显著增加到 71.25%，因为百分比从 0% 变为 100%（如图5 中的灰条所示）。与 MAMADROID 相比，<strong>DroidEvolver 对带有真实标签的模型更新不太敏感</strong>，表现也好得多。</p><ol type="1"><li><p>原因一：当没有真正的标签时，DroidEvolver 能够从漂移应用程序的伪标签中学习</p></li><li><p>原因二：每个漂移应用程序的<strong>伪标签是通过加权投票产生的</strong>，将老化模型排除在模型池中，这有助于减轻任何单一检测模型的偏差，并生成更可靠的伪标签</p><p>当某些应用程序的真实标签可用于模型更新时，DroidEvolver 不仅在功效方面，而且在效率方面都优于 MAMADROID。 <strong>DroidEvolver 可以通过带有真实标签的单个测试应用程序执行即时模型更新</strong>，但 MAMADROID 需要反复进行再训练，将所有带有真实标签的可用测试应用程序纳入训练集。</p></li></ol><p>​ 通过漂移应用程序更新DroidEvolver中的老化模型的重要性，可以通过测试一个<em>天真的解决方案</em>来进一步证明其合理性，该解决方案没有识别漂移应用程序，也没有执行更新：相反，每个应用程序的分类结果由所有检测模型通过加权投票生成。图 6将 DroidEvolver 的表现与默认设置中的天真解决方案进行了比较。它表明，天真的解决方案的F测量明显低于 DroidEvolver 后，运行了几年。天真的解决方案在恶意软件检测加班中效果较差，因为越来越多的检测模型在恶意软件检测过程中老化，因为没有执行任何更新。</p><p>​ 虽然天真的解决方案不如 DroidEvolver 有效，但它仍然大大优于 MAMADROID。在同一实验环境中，其平均F测量比MAMADROID高1.88倍。原因是，在天真的解决方案中执行的加权投票有助于缓解单个检测模型的偏差，从而即使在没有模型更新的情况下也产生更可靠的检测结果。</p><h3 id="识别漂移应用和老化模型的影响">4.4、识别漂移应用和老化模型的影响</h3><p>​ 分析 JI 值的分布，以显示在检测过程中识别漂移应用和老化模型的重要性。我们的分析是在默认设置中执行的，其中 DroidEvolver 使用 2012 年应用进行了微调参数评估。<span class="math inline">\(τ_0 = 0.3\)</span>，<span class="math inline">\(τ_1= 0.7\)</span> 和 <span class="math inline">\(K = 500\)</span>。仅展示一个模型（即PA）分布的 JI 值，因为对其他模型的分析结果类似。所选的检测模型显示出老化迹象，对 2012 年开发的新应用进行了 3.55% 的分类。当使用后期开发的应用程序进行评估时，此百分比保持稳定（没有显示更多老化迹象），这表明 DroidEvolver 执行的更新使检测模型变慢老化。</p><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu8-p16-xu-small.gif" alt="图 8： - 2012 年开发的漂移应用中的 TP、FN、TN 和 FP 的分布"></p><p>​ 图7 显示用于分配 JI 值的箱线图。这些框从下四分位数延伸到 JI 值的上四分位数，其中手段和中位数分别标有实心三角形和线条。线从箱中延伸，以显示 JI 值的第 5个百分位和第95个百分位。灰色基线标记 <span class="math inline">\(τ_0\)</span> 和 <span class="math inline">\(τ_1\)</span>，每个红色滤点表示漂移应用程序的无效 JI 值。</p><p>​ 图7a 和 图7b 分别显示了 JI 分发的真实恶意应用程序和真正的良性应用程序，<strong>大多数正确的预测（即这些数字中的第一列）都与有效的 JI 值相关联，而大多数错误预测与无效的 JI 值相关联</strong>。在大多数情况下，如果应用程序没有漂移，检测模型可以做出正确的预测：否则，检测模型会老化，可能会错误地对漂移应用程序进行分类。因此，DroidEvolver 通过将所有老化模型排除在加权投票之外，为每个漂移应用生成分类结，然后，<strong>它根据每个漂移应用程序及其伪标签使用在线学习算法更新所有老化模型</strong>。在所有检测模型在分类漂移应用程序时老化的极端情况下，加权投票由所有模型执行，并且在任何模型上不执行任何更新。</p><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu7-p16-xu-small.gif" alt="图 7： - 一个检测模型的 JI 值分布"></p><p>​ 然后，我们分析已识别的漂移应用程序，以证明漂移应用的影响。该实验在默认设置中执行，其中DroidEvolver分别从2012年、2013年、2014年、2015年和2016年的测试应用程序中识别出1459、1308、1242、1267和1183个漂移应用程序。由于所有漂移应用程序和相应的伪标签都用于更新已识别的老化模型，因此伪标签的正确性对于DroidEvolver的检测表现非常重要，<strong>带有错误伪标签的漂移应用程序可能会错误地更新老化型号</strong>。图8 显示了 2012 年漂移应用程序中的 TP、FN、TN 和 FP 的分布情况。对于所有已识别的漂移应用程序，DroidEvolver 正确地将其中 98.22% 分类为良性或恶意。其余 1.78% 的漂移应用程序具有不正确的伪标签可能会误导DroidEvolver生成不正确的分类结果，并导致恶意软件检测加班的 F 措施的下降。</p><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu10-p16-xu-small.gif" alt="图10： - 新特征的分布"></p><h3 id="特征演变">4.5、特征演变</h3><p>​ <strong>DroidEvolver 的一个主要优点是其特征集没有固定。</strong>它通过吸收在检测过程中从漂移应用程序中提取的新特征而生长。这一优势有助于 DroidEvolver 适应应用演变和Android框架演变带来的新特征。</p><p>​ 图9 显示了在默认设置中的特征演变，其中 DroidEvolver 在 2011 年训练集中启动，并在 2012 年至 2016 年开发的应用程序中进行了测试。特别是，图9a 显示，在六年内，提取特征的实际数量从 14,327个增加到 52,001个。模型池中每个检测模型的特征设置指标也观察到类似的增长模式：例如，图 9b 展示了一个检测模型（即PA）的特征设置指标的增长。类似的增长模式表明<strong>（i） DroidEvolver 可以更新其特征集，以包括从漂移应用程序中发现的新特征，（ii）DroidEvolver 的检测模型被更新，以适应恶意软件检测的新特征随着时间的推移</strong>。</p><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu9-p16-xu-small.gif" alt="图 9： - 特征演变"></p><p>​ 每年添加到特征集的新特征可以被认为是来自两个来源，包括<strong>应用程序演变和 Android 框架演变</strong>。应用程序演变意味着新特征是训练集中未用于任何应用程序或以前处理过的任何漂移应用程序的现有 API。Android 框架的演变意味着新特征是添加到 Android 规格中的新 API。</p><p>​ 图10显示，<strong>大多数新特征来自应用程序演变</strong>，而Android框架演变的贡献不容忽视。请注意，新特征的分布可能会在不同的实验设置中更改。尽管如此，应设计一个缓慢老化的恶意软件处理系统，以适应新特征，并随着时间的推移在恶意软件检测中很好地利用它们。</p><p><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu11-p16-xu-small.gif" alt="图 11： - TPs、FN、TN 和 FP 的特征 权重分布"></p><h3 id="假阳性和假阴性">4.6、假阳性和假阴性</h3><p>​ 为了解释为什么误分类假阳性和假阴性，DroidEvolver 为检测到的应用程序的每个特征输出了权重值，特征的权重值表示该特征对分类结果的贡献程度。特别是，应用程序的特征 权重被计算为（<span class="math inline">\(∑_{j∈S} w_j * x\)</span>）， 其中 <span class="math inline">\(S\)</span> 集在模型池中参与加权投票，<span class="math inline">\(w_j\)</span> 是应用进行加权投票时 <span class="math inline">\(S\)</span> 中每个模型的权重向量，<span class="math inline">\(x\)</span> 是该特征的一热向量。请注意，应用程序所有特征的权重之和正是加权投票的结果，该投票用于得出应用程序的分类结果。对于恶意（分别为良性）应用，非负（分别为负）权重显示相应特征对其检测有积极贡献，而权重的绝对值表示贡献有多大。</p><p>​ 然后，我们介绍了对假阳性和假阴性进行详细分析，其中 DroidEvolver 对 2012 年的 11,566 份申请进行了评估（包括 5,789 份良性申请和 5,777 份恶意应用）。在这种情况下，DroidEvolver 实现 F-score 95.69%，精度95.91%，真阳性率 93.39%，假阳性率1.70%。</p><p>​ <strong>特征权重分布。</strong>我们首先分析真正 （TPs）、假负数 （FN）、真负子 （TN） 和假阳性 （FP） 的特征 权重分布。图 11显示 16 个随机选择应用程序（包括 4 个 TP、4 个 FN、4 个 TN 和 4 个 FP）的框和胡须图，其中每个框从下四分位数延伸至某些应用特征权重的上四分位数，胡须从框中延伸以显示特征权重的第 5<em>个</em>百分位和<em>第 95</em>个百分位， 特征值的平均值（中位数，分别）在框内标有实心三角形（线），框内的灰色基线标记值为零，每个红色滤点（分别表示绿色滤点）表示非负 权重特征（分别为负重特征）。</p><p><a href="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu.t3-p16-xu-large.gif"><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu.t3-p16-xu-small.gif" alt="表三 - FP 非负 权重特征 （NNWF） 分布"></a></p><p><a href="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu.t4-p16-xu-large.gif"><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu.t4-p16-xu-small.gif" alt="表四 - FN 负 权重特征 （NWF） 分布"></a></p><p>​ 图11显示，FPs（见图11d）的特征 权重分布与TPs（见图11a）的特征权重分布比TN（见图11c）的特征权重分布更相似，因为大多数特征权重是非负的。另一方面，FN（见图11b）的特征权重分布与TN（见图11c）的分布更相似，而不是TP（见图11a），从某种意义上说，大多数特征权重都低于零。</p><p>​ <strong>假阳性。</strong>从 5,789 良性应用开始，DroidEvolver 产生 98 FP（即假阳性率 = 1.70%）。表三显示这些 FP 的非负权重特征的分布。如 表3a 所示，所有这些FP在从其apk文件中提取的所有特征中都拥有超过40%的非负权重特征。虽然他们的真实标签是良性的，90.91%的他们有比负权重特征更多的非负权重特征。在前 100 个显著特征中，表3b 进一步表明，所有这些 <strong>FP 具有比负权重特征更多的非负权重特征</strong>。这些解释了为什么这些应用程序被 DroidEvolver 错误预测。在这些 FP 提取的前 100 个显著特征中，我们发现一些常见的非负权重特征，如：<em>android.-content.pm.PackageManager:getApplicationInfo</em>。这<strong>些 API 通常被恶意软件用于获取有关用户设备的个人信息并检查已安装的应用程序</strong>。</p><p>​ <strong>假阴形。</strong>DroidEvolver 在其检测阶段（即 FNR = 6.61%）从 5,777 个恶意应用程序生成 382 个 FN（假阴性）。表四显示这些 FN 的负权重特征的分布。如 表4a 所示，93.33% 的 FN 具有比非负权重特征更多的负权重特征。在前 100 个显著特征中，表 IVb显示 <strong>85% 的 FN 包含的负权重特征多于非负权重特征</strong>。由于大多数特征都与负权重相关，因此除非检查比 API 调用更多的特征，否则 DroidEvolver 很难纠正对这些 FN 的检测。</p><h3 id="运行时间表现">4.7、运行时间表现</h3><p>​ DroidEvolver 的运行时间表现在检测阶段进行评估，并与具有 4<em>×</em>3.2 Ghz Intel-Cores和 12 GB RAM 的机器上的 MAMADROID 进行比较。对于运行时间评估，DroidEvolver 和 MAMADROID 均在 2011 年训练集中进行初始化、训练，并在 2012 年数据集上进行测试。</p><p>​ 表五总结了 DroidEvolver 和 MAMADROID 在平均情况下的运行时间表现：</p><p>​ 表5a 所示，DroidEvolver 器的表现瓶颈是预处理器，它分解 apk 文件以获取字形码。DroidEvolver 平均只需约0.05秒进行分类和进化，包括漂移应用识别、应用分类和必要的老化模型聚光化。通过使用可轻松提取为检测特征的 API 调用，并应用在线学习算法快速更新检测模型，DroidEvolver 平均需要 1.37s 才能在检测阶段处理每个未知应用。</p><p>​ 表5b所示， MAMADROID 在同一实验环境中的运行时间表现。MAMADROID 的第一步是”调用序列提取“，它使用 Soot 和 FlowDroid 提取 API 调用图，并将提取的 API 调用抽象到其包中。此步骤平均每个应用程序需要 37.29s，这是 MAMADROID 的瓶颈。第二步是建立一个马尔科夫链模型，并构建一个特征向量，这需要平均约0.43秒。最后，MAMADROID 平均需要大约 0.0036s 才能将特征向量分类为良性或恶意。MAMAROID 在检测阶段平均需要 39.15 秒才能处理每个未知应用程序，这比 DroidEvolver 慢 28.58 倍。</p><p>​ 如表五所示，<strong>除分类和演化外，DroidEvolver 在所有模块中都明显快于 MAMADROID</strong>。虽然分类未知应用的特征向量和更新老化模型（即 3.22 × 10 + 3s 平均）是轻量级的，它占主导地位，以确定漂移应用程序和相应的老化模型。尽管 DroidEvolver 利用 App数组 在有效性和效率之间取得平衡，但<strong>计算每个未知应用程序的 JI 值需要与 App数组 中包含的所有应用程序进行比较，需要比其他步骤更长时间</strong>。</p><p><a href="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu.t5-p16-xu-large.gif"><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu.t5-p16-xu-small.gif" alt="Table V- 在数据检测阶段对未知应用进行处理所消耗的时间"></a></p><p>​ 然后，在 图12 的<strong>初始/训练阶段和检测阶段</strong>分别评估 DroidEvolver 和 MAMADROID 的运行表现。如 图12a 所示，随着训练集的规模从10,000增加到50,000，DroidEvolver 的初始阶段所需的时间从3s增加到27s。在同一环境中，MAMADROID 的训练阶段从 26 秒增加到 1,207 秒，<strong>比 DroidEvolver 慢 8.67 到 44.70 倍</strong>。</p><p><a href="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu12-p16-xu-large.gif"><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/8790377/8806708/8806731/xu12-p16-xu-small.gif" alt="Fig. 12: - 运行时间评估"></a></p><p>​ 在其<strong>检测阶段</strong>，DroidEvolver 和 MAMADROID 的运行表现与它们处理的应用程序数量是线性的。图12b 显示了他们在检测阶段处理每个应用程序的平均表现，表明 <strong>MAMADROID 明显慢于 DroidEvolver</strong> 。</p><p>​ DroidEvolver 的高效在几个方面都取得了成功。</p><ul><li><strong>首先，DroidEvolver 利用在线学习算法从单个漂移应用程序更新其老化模型，而不是像所有批次基于学习的恶意软件检测系统一样从应用程序集合中学习</strong>。此更新过程使DrodEvolver 能够高效地按顺序处理一系列应用程序。DroidEvolver 不需要定期使用累积数据集进行任何再训练，以跟上应用演变和 Android 框架演变的趋势。</li><li><strong>此外，DroidEvolver 不需要真正的标签可用于更新其模型池在检测阶段</strong>。相比之下，大多数现有的恶意软件检测系统依赖于定期模型再训练来更新其检测模型，此类模型再训练需要在原始训练集之外对一组新应用程序进行手动标记，而该新应用受到可用资源的限制。此外，DroidEvolver 应用提取的Android API调用作为检测特征，它可以很容易地从分解字形码中检索，而无需复杂的过程，如那些在 Soot，FlowDroid和 TaintDroid 执行。</li><li>最后，<strong>DroidEvolver 应用 App数组</strong>，在不降低检测表现的情况下加快 JI 计算过程。</li></ul><h3 id="稳健性">4.8、稳健性</h3><p>​ <strong>DroidEvolver 可抵御常见的代码混淆，包括标识符重命名、垃圾代码插入、代码重新编序和数据加密</strong>。此类代码混淆可能会避开许多现有的商业反恶意软件工具。</p><p>​ <strong>DroidEvolver 具有识别码重命名类型的混淆（如重新签名、重新包装和更改类/字段/字段/方法名称）的弹性</strong>，因为 DroidEvolver 不依赖于特定的应用程序签名或类/字段/方法名称来检测恶意软件，DroidEvolver 还具有对垃圾代码插入的弹性，该插入将垃圾代码段插入应用源代码。如果插入的垃圾代码段不包括 Android API 调用，则此类垃圾代码段不会由 DroidEvolver 提取，因此不会影响 DroidEvolver 的表现。此外，DroidEvolver 是强大的代码重新编序类型的混淆，这改变了模糊应用程序的控制流逻辑。DroidEvolver 是强大的，因为它利用没有控制流逻辑的恶意软件检测。DroidEvolver 也非常适用于数据加密类型的代码混淆，因为它们加密字符串和阵列而不修改应用程序源代码中的原始 API 调用。</p><p>​ 我们通过应用 Droid-Chameleon 来模糊 2012 年数据集中随机选择的 100 个恶意应用程序，从而测试 DroidEvolver 的稳健性。DroidChameleon 是 11 种典型混淆技术的框架，包括 （1）标识符重命名：拆解和重新组装、类重命名、方法重命名和字段重命名；（2）垃圾代码插入：垃圾代码插入和 Nop 指令；（3） 代码重新排序：代码重新排序、订单倒转和特征间接插入；（4） 数据加密：字符串加密和阵列加密。我们将 11 种混淆技术中的每一种应用到 100 个选定的恶意应用程序中，生成 1,100 个模糊的应用程序。在 2011 年数据集上初始化后，DroidEvolver 可以成功检测 96% 的模糊应用。对于 11 种混淆技术中的每一项，DroidEvolver 有 <strong>4%的假阴性</strong>。在手动检查了这 44 个假阴性后，我们发现它们都来自四个恶意应用程序。我们进一步测试了 DroidEvolver 在这四个恶意应用程序，发现 DroidEvolver 也判断错误。因此，DroidEvolver 错过了这 44 个模糊的应用程序，不是因为它们被混淆了，而<strong>是因为它们即使没有混淆也错过了。</strong></p><p>​ 强攻击者可能会在对抗性采样中小心地制作恶意软件，以逃避恶意软件检测和误导检测模型。对抗性样本制作的一个例子是<strong>将选定的扰动引入某些恶意应用程序的特征向量，以便扰动特征向量上的检测结果为良性</strong>。 考虑一个强大的攻击者谁知道 DroidEvolver进化机制和状态，包括模型池中的所有检测模型，以及应用程序缓冲器中的所有特征向量，在任何时候。此类攻击者可能会在特定时间制作一个特征矢量来逃避恶意软件检测，或创建一组特征矢量来误导 DroidEvolver 的演变。但是，对于此类攻击者来说，从精心制作的特征矢量构建真实世界恶意应用程序仍然具有挑战性，<strong>因为从由精心制作的特征矢量定义的 Android API 固定列表中实现某些目的驱动的恶意特征并非微不足道。它仍然是今后研究如何大规模地进行此类攻击的研究方向。</strong></p><h3 id="限制和扩展">4.9、限制和扩展</h3><p>​ DroidEvolver 是一种静态分析系统，根据其字形码中包含的一组 Android API 调用检测恶意软件。它无法检测<em>只能根据更复杂的特征（如 API 调用图和字节码语义）检测到的恶意软件</em>。如果在静态分析（如动态加载的恶意代码和运行时间恶意行为）中看不到恶意软件的 API 调用，则可以避开 DroidEvolver 。从<strong>在线学习中继承下来的 DroidEvolver 的另一个局限性是，它容易受到中毒攻击</strong>。在中毒攻击中，攻击者可能会故意为 DroidEvolver 制作初始化数据集，使其无法有效检测某些恶意软件。</p><p>​ 为了解决这些限制，<strong>DroidEvolver 可以扩展为使用任何其他检测特征，而不是一组 API 调用</strong>。这种扩展是可行的，因为 DroidEvolver 的核心模块，包括模型池的构建、分类和演化，独立于其他模块中特征向量的生成方式。通过在静态分析中插入 API 调用图和控制流图等更复杂的特征，DroidEvolver 可能会在表现开销上实现更高的回报。只要能够生成并用于此类分析，DroidEvolver 也可以扩展到本地代码分析和动态分析。虽然我们目前的工作重点是设计和评估具有轻量级检测特征的 DroidEvolver 机制，但我们未来的工作将转向将 DroidEvolver 扩展到其他检测特征。</p><p>​ 为了阻止中毒攻击，我们<strong>建议将 DroidEvolver 扩展到初始阶段包括消毒模块</strong>。对于初始化数据集中的每个应用程序，消毒模块要求模型池中的每个检测模型根据当前模型结构生成分类标签。如果模型池中的大多数检测模型无法就应用程序的分类标签达成一致，消毒模块可能会认为应用程序”中毒“，并将其从初始化数据集中删除。此消毒过程可以分几轮（每次从零开始）执行，随机重新洗牌初始化数据集。初始化数据集经过消毒后，可以初始化 DroidEvolver 进行恶意软件检测。</p><h2 id="相关工作">5、相关工作</h2><p>​ 在过去的几年里，Android恶意软件检测引起了学术界和业界的广泛关注。DroidEvolver 更与基于机器学习的 Android 恶意软件检测系统相关。</p><p>​ <strong>老化问题。</strong>MAMADROID 是一个Android恶意软件检测系统，由于对包和家庭的抽象 API 调用，该系统能够抵御 Android API 更改。MAMADROID 中的检测模型不会在检测阶段由各个应用程序自动更新，因为它是从批量学习算法构建的。为了保持其恶意软件检测的有效性，可以重新训练一组新的应用程序，然而，这种再训练受制于再训练中使用的应用程序是否提供真实标签。相比之下，DroidEvolver 不需要真正的标签来证明模型在检测阶段的演变。</p><p>​ <strong>另一项相关工作是Transcend</strong>，是检测恶意软件分类模型中概念漂移的框架。在 DroidEvolver 中识别漂移应用和老化模型的重要性是由 Transcend 推动的；但是，在超越中为检测概念漂移而提出的统计指标不能直接应用于 DroidEvolver，因为 Transcend 通过将其与所有且仅具有真实标签的训练应用程序进行比较来计算每个测试应用程序的概念漂移指标。概念漂移指标无法捕获每个测试应用程序与检测阶段中没有真实标签的任何新应用有何不同。Transcend 和 DroidEvolver之间的另一个区别是，<strong>Transcend 专注于如何检测概念漂移，而不涵盖如何开发一个减慢，可扩展和强大的恶意软件检测系统，以有效的恶意软件检测随着时间的推移</strong>。</p><p>​ <strong>恶意软件检测中的在线学习</strong>。近年来，在线学习算法已应用于 Android 恶意软件检测。例如，DroidOL 和 CASANDRA 使用在线学习算法构建恶意软件检测模型，并根据其 API 调用图对 Android 应用程序进行分类。DroidOL 和 CASANDRA 在收到每个标记应用程序后，都会使用在线学习算法自动重新训练其检测模型，并使用更新的检测模型对未标记的应用程序进行分类。再训练过程要求每个应用程序与其真实标签相关联，而该标签受可用资源的限制。相比之下，DroidEvolver 在检测阶段自动更新其检测模型不需要真正的标签，这回避了在初始化阶段后标记任何应用程序的必要性。<strong>与这些现有方法不同，DroidEvolver 依靠模型池而不是任何单一的在线学习算法来生成其检测结果</strong>。模型池可以帮助检测和减轻任何单一检测模型的偏差，从而产生更可靠的检测结果。</p><p>​ <strong>其他恶意软件检测方法</strong>。与DroidEvolver不同，大多数基于学习的恶意软件检测系统依靠频繁的再训练来保持其在恶意软件检测中的有效性，而再训练则在一组标记应用程序上进行，包括超越之前训练集的新应用。下面提供了此类恶意软件检测系统的不完整列表：6ThSense利用三种不同的机器学习技术（即马尔科夫链、朴素贝叶斯和 LMT）来检测与手机传感器相关的恶意行为。StormDroid 使用各种机器学习算法，如 SVM、决策树和朴素贝叶斯，根据已使用的权限、敏感的 API 调用和敏感的 API 调用序列来检测恶意软件。MARVIN 应用线性逻辑回归模型，从静态分析和动态分析中衍生出的大量特征中对 Android 应用程序进行分类。DroidMiner 还使用各种机器学习算法，包括 SVM、决策树、朴素贝叶斯和随机森林来检测敏感 API 名图上的恶意软件。Drebin 根据请求权限、应用组件和可疑的 API 调用将 SVM 应用于恶意软件检测。最后，DroidSIFT 根据上下文 API 依赖性图生成的特征向量执行基于异常的检测和基于签名的检测。</p><p>​ 最近，在如何使用深度神经网络进行更好的恶意软件检测方面，我们做出了努力。例如，, DroidDetector 和 Droid-Sec使用 192 个人工工程特征构建了 Android 恶意软件检测的深度置信网络，包括所需的权限、敏感的 API 调用以及从 DroidBox 获得的某些动态行为。Deep4maldroid 构建了来自 Linux 内核系统调用的加权定向图形，并将其用于训练深度神经网络进行 Android 恶意软件检测。Mclaughlin 等人使用深层神经网络根据每个应用程序如何使用 218 dex 指令来检测 Android 恶意软件。DeepRefiner 使用两个具有不同深神经网络的检测层从不同角度检测 Android 恶意软件。FeatureSmith 使用自然语言处理技术从科学文献中生成恶意软件检测特征。</p><p>​ 除了基于学习的恶意软件检测系统外，还提出了庞大的基于签名的恶意软件检测系统。例如，Kirin 根据要求的权限检测恶意软件，这些权限违反了某些预先定义的安全规则。</p><h2 id="结论">6、结论</h2><p>​ 本文介绍了DroidEvolver，一个有效和高效的 Android恶意软件检测系统，可以自动更新自己，以赶上恶意软件和 Android框架的快速演变。与大多数基于学习的恶意软件检测系统不同，DroidEvolver 应用在线学习算法对其具有不断发展的特征集的检测模型进行必要的更新。后者依靠批量学习算法生成具有固定特征集的不可变的检测模型。虽然大多数现有的恶意软件检测系统可以通过对一组带有真实标签的新应用程序进行再训练来更新，但 DroidEvolver 既不需要再训练，也不需要真实标签来更新自己。因此，在资源约束设置中，DroidEvolver 更为实用，因为许多新应用程序无法及时获得真实标签。严格的实验表明，随着时间的推移，DroidEvolver 在准确性和效率方面的表现始终高于恶意软件检测的先进水平，DroidEvolver 也显示强大的对几个典型的代码混淆技术。将来，我们计划在静态分析和动态分析中使用 Android API 调用以外的恶意软件检测特征扩展 DroidEvolver 。最终目标是提高 DroidEvolver 的准确性，以更新真正的标签。我们目前的工作为实现这一最终目标迈出了有希望的第一步。</p>]]></content>
    
    
    
    <tags>
      
      <tag>论文翻译</tag>
      
      <tag>Android Malware</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>FB2Droid - A Novel Malware Family-Based Bagging Algorithm for Android Malware Detection</title>
    <link href="/2021/11/15/FB2Droid/"/>
    <url>/2021/11/15/FB2Droid/</url>
    
    <content type="html"><![CDATA[<h2 id="摘要">摘要</h2><p>​ 随着 Android 恶意软件应用程序数量持续高速增长，检测恶意软件以保护系统安全和用户隐私变得越来越紧迫。每个恶意软件应用程序都<strong>属于特定家族</strong>，恶意软件<strong>家族之间存在数量差距</strong>。如果很好地利用恶意软件家族信息并采用某些策略来平衡样本之间的变异性，则检测的准确性可以得到提高。此外，基础分类器的性能有限。如果可以采用集成分类器或集成方法，检测效果可以进一步提高。因此，本文提出了<strong>一种新的基于恶意软件的基于家族的Bagging算法</strong>，用于 Android 恶意软件检测，称为 <strong>FB2Droid</strong>。首先，从安卓应用程序包中提取了五个特征。然后，将<strong>解压特征选择算法</strong>用于<strong>特征选择</strong>。接下来，我们根据不同恶意软件系列设计了<strong>两种不同的采样策略</strong>，以缓解数据集中的样本不平衡。结合两种取样策略，改进了传统的Bagging算法，以集成分类器。在实验中，使用了几个分类器来评估这两种采样策略。实验结果表明，建议的取样策略和改进的Bagging算法可以有效地提高这些分类器的检测精度。</p><h2 id="简介">1、简介</h2><p>​ 近年来，Android操作系统发展迅速，是<strong>智能手机操作系统使用最广泛的系统</strong>。根据《全球统计》最近的一份报告 。截至2019年4月，Android设备在所有智能手机用户中的市场份额最高，占74.85%。除了它的受欢迎程度，它也引起了恶意软件开发者的注意。关于 Android 恶意软件，根据 McAfee 移动威胁报告 2020，2019 年第 4 季度检测到的移动恶意软件总数超过 3500 万。恶意软件的惊人增长对用户构成巨大威胁。因此，检测恶意软件和保护用户安全迫在眉睫。</p><p>​ 随着机器学习算法的发展和普及，它们被广泛应用于Android恶意软件检测领域。基于机器学习的恶意软件检测主要包括以下步骤：</p><ol type="1"><li>数据<strong>收集和整理</strong>，以及<strong>分析</strong>良性和恶意样本，并提取特征；</li><li>使用<strong>特征选择算法</strong>筛选提取的特征；</li><li><strong>训练</strong>分类模型；</li><li>使用分类模型<strong>检测和判断</strong>未知样本</li></ol><p>​ 根据不同的特征提取方法，Android恶意软件检测可分为静态分析和动态分析。</p><p>​ 静态分析使用逆向工程来分解 Android 应用程序包 （APK），而无需安装和执行应用程序，然后从代码和其他文件中提取特征。与静态分析不同，动态分析需要运行应用程序，然后收集有关运行内容以提取特征的信息。这种方法在识别恶意活动时可以达到很高的准确性，但实时运行监视器需要很长时间和巨大的资源。相比之下，静态分析技术由于资源消耗低、代码覆盖率高而得到广泛应用。</p><p>​ 安卓恶意软件检测问题本质上是一个分类问题。随着恶意软件的飞速发展，各类恶意软件也越来越多。<strong>根据恶意软件的行为和特征</strong>，恶意软件可以分为不同的家族。但是，不同恶意软件家族的发展不平衡，样本数量差异很大，导致检测不平衡。换句话说，某一类型的大量样品导致分类器对此类样品的"偏差"，从而影响检测效果。传统分类算法在平衡数据集中取得了良好的效果，但实际数据集往往不平衡，传统算法对不平衡数据敏感，检测效果较差，如 SVM 和 Rf 。数据不平衡表现在两个方面：</p><p>​ 类间不平衡，其中数据集中一个类的样本数量明显少于其他类别的样本数量</p><p>​ 课内不平衡，其中一个类及其子类中的样本数不平衡或一类数据呈现多个小的分离术语</p><p>​ 由于传统分类器以整体分类精度为学习目标，在这种情况下，要获得更高的分类精度，势必导致分类器过分关注大多数类样品，从而降低少数类样品的分类性能。目前，<strong>大多数恶意软件检测方案忽视了内部的不平衡</strong>，即恶意软件内部各种软件家族之间的不平衡，导致训练有素的分类器对样本量大的家族具有更好的检测性能，但对样本数量较少的家族的检测性能较低，从而降低了整体检测效率。此外，大多数现有的 Android 恶意软件检测方案仅使用特征和有效性的单个分类器。</p><p>​ 因此，为了解决上述问题，本文提出了一种新的<strong>基于恶意软件的家族装袋算法</strong>，用于Android恶意软件检测。首先，该方案从 APK 文件中提取五个特征，然后使用解压特征选择算法来<strong>评估每个特征的重要性</strong>，然后<strong>选择一些更重要的功特征</strong>进行分类器训练和恶意软件检测。然后，根据数据集中提供的家族标签，设计了<strong>两种采样策略</strong>，以<strong>缓解数据集中的类内不平衡</strong>。然后，设计策略用于改进装袋算法，以集成分类器以检测恶意软件。实验结果表明，使用基于一些通用分类器的拟议集成方案，<strong>恶意软件的检测精度</strong>和<strong>F-score</strong>提高了2.3%和2.0%。</p><p>​ <strong>本文的贡献如下：</strong></p><ol type="1"><li>恶意软件的<strong>家族信息和类别标签</strong>应用于恶意软件检测，并构建了基于恶意软件家族的集成 Bagging 方案，以有效提高恶意软件检测的准确性。</li><li><strong>考虑到恶意软件家族之间的不平衡，改进了 Bagging 的采样策略</strong>。在基于经典 Bagging 算法的随机抽样的基础上，增加了两种取样方法：基于恶意软件家族数量的等数取样策略和基于恶意软件家族信息的取样策略。</li><li>设计的抽样策略考虑到了恶意软件家族之间的不平衡，可以有效缓解班级内部的不平衡，并充分照顾每个恶意家族。</li><li>我们设计并进行了多项实验，并提出了有效的实验成果。实验结果表明，建议方案的可行性和有效性。</li></ol><h2 id="相关工作">2、相关工作</h2><p>​ Android 恶意软件检测技术分为三类：静态分析、动态分析和混合分析。</p><p>​ 静态检测使用相应的分解工具提取程序的静态特性，如语法语义和签名，用于分析，以评估应用安全性和检测恶意软件。</p><p>​ 静态分析可以进一步细分。一个是基于签名的恶意软件检测，基于签名的静态分析方法主要使用应用软件的独特签名机制来唯一识别应用程序的签名和特征代码，并将其与已知的恶意软件特征基础进行比较，如果与一致签名匹配，则判断为恶意软件。Faruki 等人提出了 <strong>AndroSimilar</strong>，这是一种通过提取统计学上强大的特征来检测恶意 Android 应用程序来生成签名的方法。郑等人提出了的 <strong>DroidAnalytics</strong>，一个基于签名的检测和分析系统，可自动收集、管理、分析和提取 Android 恶意软件，它使用多级签名算法（签名包含方法级别、类级和应用级别）根据 <strong>操作码级别</strong>语义提取恶意软件特征，与传统加密方法（例如基于 md5 的签名）相比，多级签名方法具有重要优势。但是，该技术存在一些局限性，在用于检测重新包装的恶意软件时，无法高精度地解决问题。而且，随着恶意应用的爆炸式增长，<strong>需要不断提取新的恶意应用特征签名代码</strong>，这在一定程度上增加了工作量，效率太低。这产生了一种替代静态分析方法，该方法使用多个静态特征来检测恶意软件。为此，可执行应用程序 （APK） 经过逆向工程，从中提取相关特征以进行分析和检测，例如 API 、权限、意图、特征调用图、控制流图。Aorar等人提出了一种名为 <strong>PermPair</strong> 的新型检测模型，它通过挖掘来自 AndroidManifest 的权限组合来检测恶意软件.xml 应用程序。Niu等人使用函数调用构建<strong>函数调用图</strong>来分类 Android 恶意软件。本文使用了<strong>操作码级函数调用图</strong>，这是通过对操作代码 （OpCode）的静态分析获得的。然后，作者应用长期短期存储器（LSTM）来检测应用程序。</p><p>​ 动态分析不同于静态分析，可实时监控程序的运行，以查找和检测程序的恶意行为。其中，动态特征包括网络流量 。系统调用和资源消耗。Vinod 等人提出了基于系统调用的 Android 恶意软件检测方案，结果在五个数据集上进行验证。RoughDroid 建议采用软盘分析技术，可直接在智能手机上发现 Android 恶意软件应用程序。</p><p>​ 但是，动态分析需要监控移动设备或模拟器上的应用程序以提取特征，这很费时。因此，一些学者将静态分析与动态分析相结合，进行混合分析。在“A hybrid detection method for android malware”，作者提出了一种混合检测方法，对静态检测检测的这些可疑应用进行动态检测。在作者从良性和恶意应用程序（如 API 呼叫序列、系统命令、显性权限和意图）中汇编了静态和动态特征。然后，他们使用深层神经网络对应用程序进行分类。在 [31•，作者应用网络相关特征和活动大拉姆构建一个检测方案，以解决基于机器学习和混合分析的Android恶意软件家族分类问题。提出了广泛的特征集，包括网络相关特征和活动大拉姆。本文提出的方案属于静态分析。</p><p>​ 随着 Android 恶意软件的快速发展，有多种不同类型的恶意软件，根据恶意软件的特点可分为不同的家族。恶意软件家族的分类也是恶意软件检测的重要组成部分。但是，数据集中存在多种恶意软件家族，它们之间的分布不平衡，因此很难检测到恶意软件。因此，许多学者已经开始关注这一方向，希望通过对恶意软件家族的分类来提高检测效率。EC2提出了一种新的算法，用于发现大小不一的 Android 恶意软件系列从非常大到非常小的家族（微乎其微）。Fan等人提出了一种构建<strong>Fregraphs</strong>以表示属于同一家族的恶意软件样本的常见行为的新方法，对 Android 恶意软件进行分类，并根据<strong>Fregraph</strong>选择<strong>具有代表性的恶意软件示例</strong>。然后，他们设计并实施了一个新的检测系统<strong>FalDroid</strong>，它可以<strong>处理大规模Android恶意软件的家族分类</strong>，高精度和高效率。本文仅使用恶意软件的家族信息来改进 Bagging 算法来检测恶意软件。</p><p>​ 由于机器学习的发展，它已广泛应用于Android恶意软件检测。但是，很难通过使用单个基础分类器（如支持矢量机 （SVM））来改进检测结果。因此，<strong>使用集成分类器进行检测已成为一种趋势</strong>。将<strong>具有独立决策能力的分类器相互组合</strong>的方法称为<strong>集成分类器（ensemble classifiers）</strong>。事实证明，集成分类器的预测能力比单个分类器的预测能力要强得多。在使用集合分类器的研究中，有两个方向：（一）是直接使用相关的组合分类器，如随机森林 （RF）、梯度提升决策树 （GBDT）、和阿达布斯特；（二）、是使用集成方法与单个分类器相结合，如提升、装袋和堆叠方法。Yerima 和 Sezer 提出了基于多层次分类器融合的检测框架 DroidFusion。此框架使用排序算法对低级训练分类模型进行排序，并选择最佳组合以产生最终决策结果。此外，在恶意软件检测领域，机器学习算法在特征提取、优化和软件检测方面具有显著优势。因此，本文选择改进Bagging算法，进一步提高多机学习的检测性能。</p><h2 id="特征提取和选择">3、特征提取和选择</h2><h3 id="特征提取">3.1、特征提取</h3><p>​ Android 恶意软件检测的数据集是原始的 APK 文件，它是 Android 应用程序的安装包。为了提取相关特征，需要对 APK 文件进行分解以获取程序代码及其关键文件。因此，在本文中，APK 使用"安德罗卫士"进行分解 。获取 AndroidManifest .xml 和 Class.dex 文件并将 Class.dex 文件转换为 .smali 文件的工具，该文件更人性化，可作为字节代码的中间演示。</p><p>​ Android 活动文件包含执行程序和通信组件所需的所有权限。因此，本文从上述两个文档中提取了以下五个特征，如图所示:</p><ol type="1"><li>权限：如果应用需要执行某些指定操作，则必须请求相应的权限</li><li>应用组件：应用程序组件是应用程序的基本构建基块，包括 activities、服务、发送器和接收器</li><li>Intent 过滤器：Intent 用来处理组件之间的通信</li><li>敏感 API 调用：某些 API 呼叫允许调用智能手机上的敏感数据和资源</li><li>敏感的shell命令：某些命令可以获得 root 特权并执行危险操作</li></ol><p><img src="https://static-01.hindawi.com/articles/scn/volume-2021/6642252/figures/6642252.fig.001.svgz" alt="图1：特征提取流程图"></p><p>​ 在实验中，为了降低资源消耗，提高检测效率，该特征以二元形式表示。如果应用程序中存在该特征，则该特征的相应位置标记为 1。否则，它被标记为 0，并且最终形成了图中显示的 0/1 的 eigenmatrix。</p><p><img src="https://static-01.hindawi.com/articles/scn/volume-2021/6642252/figures/6642252.fig.002.svgz" alt="图2：特征表示图"></p><p>​ 要进一步解释 eigenmatrix，假设样本数为<em>m</em>，特征数为<em>n</em>。因此，图的二维的艾根图2获得每个行表示示例，每个列表示一个特征。</p><h3 id="特征选择">3.2、特征选择</h3><p>​ 数据和特征决定了机器学习的上界，模型和算法只接近上界。特征选择是最大限度地从原始数据中提取特征，以便使用算法和模型。一般来说，特征选择包括以下四个步骤：</p><ol type="1"><li>生成：生成特征的候选子集</li><li>评价：评估特征子集的质量</li><li>终止：决定何时停止生成过程</li><li>验证：检查特征子集是否有效</li></ol><p>​ 特征选择技术旨在更深入地了解数据，并最大限度地减少训练和测试阶段所需的计算量，以提高预测性能。它还概括了学习模式，以减少过拟合。通常，特征选择算法分为两种方法：<strong>（a） 特征搜索 （b） 特征子集评估</strong>。特征搜索是属性空间研究中广泛应用的技术之一。在机器学习领域，特征搜索可分为前向选择和后向淘汰。特征子集评估是一种广泛用于识别不相关和冗余属性的方法。</p><p>​ 有三种类型的特征评估技术：<strong>筛选</strong>，根据差异或相关性对特征进行评价，并设置阈值以选择特征：<strong>包装</strong>，每次根据目标函数（通常是预测效果分数）选择或排除特征；<strong>嵌入</strong>是使用机器学习算法和模型进行训练的，并获得了各种特征的重量系数。特征根据从大到小的系数进行选择。相比之下，滤波器具有较高的计算效率，独立于其他分类学习方法，能有效排定特征的重要性。因此，本文选择了解压算法进行特征选择。</p><p>​ 作为一种有效的特征选择算法，Relief 算法根据每个特征和类别的相关性分配不同的权重，重量小于一定阈值的特征将被删除。Relief 算法从训练集 <em>D</em> 中随机选择 <em>样本 R</em>，然后从与 <em>R</em> 相同的类别的样本中查找最近的邻居样本 <em>H</em>（称为 <em>Near Hit</em>），从称为 <em>"Near Miss"</em> 的不同类型的<em>R</em>样本中查找最近的邻居样本 <em>M(C)</em>，然后根据以下规则更新每个特征的权重： <span class="math display">\[W(F)=W(F)-  diff(F,R,H)/m+  diff(F,R,M(C))/m \tag{1}\]</span> ​ 其中 <em>F</em> 表示样本中的一个特征，<em>m</em> 表示样本数，<em>diff(F, R1, R2)</em> 函数表示示例 <em>R</em> 之间的差异1和样品 <em>R2</em> 在特征 <em>F</em> 和 <em>M(C)</em> 代表 <em>C</em> 类中最近的邻居样本。</p><p>​ 如果特征上的 <em>R</em> 和 <em>Near Hit</em> 之间的距离小于 <em>R</em> 和 <em>Near Miss</em> 之间的距离，则表示该特征<strong>有利于区分类似种别的近邻和其他种别的近邻</strong>：然后，特征的权重将增加。相反，如果一个特征上的 <em>R</em> 和 <em>Near Hit</em> 之间的距离大于 <em>R</em> 和 <em>Near Miss</em> 之间的距离，则表明<strong>此特征对区分相似种别和不同种别的近邻有负面影响</strong>：然后，此特征的重量将减少。<strong>上述过程重复<em>m</em>次，最后获得每个特征的平均重量</strong>。因此，根据 <em>Relief</em> 算法计算的重量，本文筛选出小重量特征，有效提高了检测效率。参见部分详细描述。</p><h2 id="集成检测方案">4、集成检测方案</h2><p>基于机器学习的传统 Android 恶意软件检测方案通常只使用单个基础分类器（如 SVM）进行检测，性能有限。但是，通过组合多个基础分类器或使用集成分类器可以取得更好的结果。</p><h3 id="bagging算法">4.1、Bagging算法</h3><p>​ Bagging 算法是<strong>并行集成算法</strong>最著名的代表。在集成算法中，Bagging方法是在原始训练集的随机子集上构建一类黑匣子评估器的多个实例，然后<strong>将这些评估器的预测结果组合在一起</strong>，形成最终预测结果。该算法的思路是<strong>使学习算法训练多轮</strong>：每轮训练集由随机从原始训练集中取出的 <em>M</em> 样本组成，训练样本可以在一轮训练中多次出现或未出现（即用替换进行采样），训练后可获得预测特征。最后，通过投票解决分类问题。著名的<strong>集成分类器 <em>Rf</em></strong>， Bagging 算法加上<strong>决策树（DT）分类器</strong>， 是由布雷曼提出的 。Bagging算法的基本流程，如下算法流程所示，包括抽样、训练和分类。因此，本文提出的改进 Bagging 集成方案是抽样和最终投票分类的改进和创新。</p><blockquote><p>输入：数据集 <em>D</em>， 迭代数 <em>T</em>， 采样数 <em>n</em>， 基础分类器 <em>G(x)</em></p><p>输出：最终强分类器 <em>f(x)</em> (1) <em>t = 1,2, ...</em> (2) 训练集D随机采样 <em>t</em> 次，共抽取 <em>m</em> 次以获取包含 <em>m</em> 样本的采样子集 <span class="math inline">\(D_t\)</span> (3) 使用样品集 <span class="math inline">\(D_t\)</span> 训练基础分类器 <span class="math inline">\(G_t(x)\)</span> (4) 如果是分类算法，则采用投票策略，即 <em>T</em> 基础分类器投出最多票数的类别类别或类别之一为最终分类。如果是回归算法，则采用算术平均值，即算术平均值对 <em>T</em> 弱分类器获得的回归结果进行，获得的值为最终模型输出</p></blockquote><h3 id="抽样策略">4.2、抽样策略</h3><p>​ 传统的 Bagging 集成算法使用<strong>随机取样策略</strong>，其中<strong>每个样本的选择概率相同</strong>，但在现实中，<strong>数据不平衡</strong>，不同恶意软件家族之间的有时差距很大，即样本数量随大小而变化很大。在这种情况下，<strong>采用随机抽样的抽样组样本分布极不平衡</strong>，有些家族数量众多，识别率相对较高，而另一些家族样本的识别率很低，从而降低了整体检测性能。但是，传统的 Bagging 算法只使用随机取样策略，表现上改进有限。其次，考虑到数据集中的每个样本都属于恶意软件家族，并且家族数量也各不相同，<strong>传统的 Bagging 算法很难考虑每个恶意家族</strong>。因此，为了充分利用每个恶意软件的家族信息并提高检测性能，本文在本文中增加了两种采样策略，如图所示，基于传统的 Bagging 算法：<strong>基于恶意软件家族的等量取样策略</strong>和<strong>基于恶意软件家族信息的家族取样策略</strong>。按相同家族数量进行采样意味着训练组中的每个家族以相同数量采集良性和恶意样本，样本不足的恶意家族通过超采样来构成样本数量。</p><p><img src="https://static-01.hindawi.com/articles/scn/volume-2021/6642252/figures/6642252.fig.003.svgz" alt="图3 采样策略"></p><p>​ 家族抽样与恶意软件家族信息是<strong>基于每个样本的计算家族信息</strong>。每个恶意软件都属于特定的恶意软件家族，每个恶意软件都包含有关其家族的信息。在开始采样之前，<strong>对每个恶意软件家族进行家族信息估计器训练</strong>，以计算每个样本的家族信息。每个家族的所有恶意样本和训练集中的所有良性样本都发送到家族信息估算器进行训练，然后，<strong>每个样本中包含的家族信息作为输出</strong>。最后，每个家族应采集的样本数量根据每个恶意家族中所有样本的家族信息计算。其中，样本的恶意软件家族信息 MFI 表示样本属于家族的概率，MFI 值越高，属于家族的可能性就越大。MFI 计算公式如下： <span class="math display">\[MFI=Estimator(sample), \tag{2}\]</span> ​ Estimator()表示家族信息估计器</p><p>​ 相反，恶意样本被误判为良性应用的可能性是 <em>BFI</em>。<em>BFI</em> 计算公式如下： <span class="math display">\[BFI = 1- MFI \tag{3}\]</span> ​ 因此，在某个家族中，所有样本被误判的概率越大，检测恶意家族就越困难，参与分类器训练所需的样本就越多。因此，本文设计了以下公式来计算要采集的样本数量： <span class="math display">\[N_i=[Num(family_i )*\sum_{j=1}^{Num(family_i)}BFI_{i,j}] \tag{4}\]</span> ​ 其中 <em><span class="math inline">\(N_i\)</span></em> 表示要从 <em><span class="math inline">\(family_i\)</span></em> 中取样的样本数量，表示样本 <em>j</em> 在家族中我被误判为良性应用的可能性，以及<span class="math inline">\(Num(family_i)\)</span> 这两种新的抽样策略都基于恶意软件系列，家族数量决定取样数量。在随后的实验中，为了降低方案的复杂性，不再讨论基于恶意软件家族信息的家族抽样策略中家族信息估算器的选择，每个家族的信估计器采用相同的分类模型，<strong>分类模型取决于由组合方案集成的单个分类器</strong>。</p><h3 id="改进的装袋组合检测方案">4.3、改进的装袋组合检测方案</h3><p>​ 本文提出的组合检测方案中，<strong>每轮抽样将培养多个基础分类器，基础分类器的差异可以有效提高袋装方法的检测性能</strong>。因此，为了进一步提高基础分类器之间的差异，本文在传统的袋装算法的基础上增加了两种取样策略。因此，此方案分别使用三种采样策略，每个采样策略执行 <em>N</em> 轮。在每轮中，<em>n</em> 样本从原始训练集中作为训练子集进行选择，并选择总共 <em>3N</em> 训练子集。每个子集都对基础分类器进行训练，每个基础分类器仍然独立于其他子集。三种采样策略可以并行执行。</p><p>​ 首先，我们在分组训练中执行采样。分别采用随机抽样策略，基于恶意软件家族的等号抽样策略和基于恶意软件家族信息的家族抽样策略，并进行回放 <em>N</em> 轮抽样，每个抽样方法获得 <em>N</em> 个训练子集 <em><span class="math inline">\(D_i, i = 1,2,……n\)</span></em> 总共 <em>3N</em> 训练子集。接下来，为每个训练子集 <em><span class="math inline">\(T_i\)</span></em> 训练基础分类器。</p><p>​ 采用基于恶意软件家族信息的家族抽样策略时，应<strong>分别训练家族信息估计器</strong>，以便每个家族计算样本数量。最后，基础分类器通过根据样本的计算数量绘制样本进行训练，然后，使用<strong>具有最佳权重的加权投票策略</strong>将基础分类器组合成一个强分类器，以便测试组中的样本逐一通过每个基础分类器并执行加权投票以输出最终分类结果。在最终加权投票中，由于使用了<strong>三种不同的抽样策略</strong>，经过训练好的基础分类器的检测性能不同，不能简单地使用投票策略将每个分类器组合在一起，并且为每个分类器分配适当的权重，以进一步突出分类器之间的差异，从而提高检测效果。为了给每个基础分类器分配最佳权重，本文使用智能优化算法自动优化每个分类器的重量。因此，本文采用<strong>微分演化（DE）算法</strong>进行自适应优化。<strong>DE 算法</strong>是基于人口演变的随机搜索全球优化算法。它使用真实数字编码，包括三个基本操作：<strong>突变、交叉和选择</strong>。优化搜索以模仿生物种群之间的合作和竞争产生的启发式人口智能为指导。与其他演化算法相比，DE算法具有<strong>收敛快、操作简单、实现方便</strong>等优点。使用DE算法时，根据经验值和实验验证，将人群设置为40，进化数设置为30，缩放系数为0.5，交叉概率为0.3，分类器的精度为拟合特征，为了在实验结果中具有更大的稳定性和真实性， 使用五倍交叉验证。同时，当DE算法用于优化基础分类器的重量系数时，为了提高模型的学习效率，减少计算量，同时尽可能保证基础分类器之间的差异：同一采样算法获得的基础分类器具有相同的重量。</p><p>​ 加权投票策略的规则是将每个基础分类器的预测票数乘以其权重系数，然后汇总每个类别的加权票数，所获得值的相应类别为最终分类结果。加权投票公式如下： <span class="math display">\[R(x_i) = sign(\sum_{j=1}^{3N}w_j * C_j(x_i)) \tag5\]</span> <span class="math inline">\(w_j\)</span> 表示每个分类器的权重，<span class="math inline">\(C_j(x_i)\)</span> 表示每个分类器 <span class="math inline">\(C_j\)</span> 上 <span class="math inline">\(x_i\)</span> 的预测结果</p><p>检测方案的整体流程见图4</p><p><img src="https://static-01.hindawi.com/articles/scn/volume-2021/6642252/figures/6642252.fig.004.svgz" alt="图4 组合检测方案"></p><p>集成检测方案的基本流程如下：</p><ol type="1"><li><strong>原始数据集分为训练数据集和测试数据集</strong></li><li><strong>对于训练数据集，使用三种采样策略进行 <em>N</em> 替换取样，每个采样方法分别获得 <em>N</em> 训练子集，共 3 个 <em>N</em>子集</strong></li><li><strong>每个训练子集都训练一个基础分类器，基础分类器相互独立</strong></li><li><strong>用于优化基础分类器的重量的差分演化算法</strong></li><li><strong>让每个基础分类器检测测试数据集中的每个样本，并加权并投票结果以输出每个样本的最终分类结果</strong></li></ol><h2 id="评价">5、评价</h2><p>​ 为了验证本文提出的方案，进行了以下实验。首先，我们在训练集中显示恶意家族样本的分布情况。然后，讨论由特征选择算法优化的特征。其次，验证加权投票策略的最佳权重是否改善了效果。最后，将所提出的方案与传统的分类方法进行比较，如SVM、RF、DT、K-最近的邻居（KNN）、逻辑回归（LR）、线性判别分析（LDA）、多层感知器（MLP）、RF（随机森林算法）、AdaBoost和GBDT（梯度提升决策树）。</p><h3 id="数据集和选定特征">5.1、数据集和选定特征</h3><p>本文实验中使用的数据集包括恶意样品和良性样本。恶意样本主要来自 AMD 数据集包含 71 个家族，共包含 24,553 个恶意软件样本，广泛应用于 Android 恶意软件检测领域。良性样本来自谷歌游戏商店和 Apkpure 。同时，为了确保实验的有效性，良性数据集的应用包括体育、商业、游戏、教育、新闻等类别，并充分考虑了Android应用程序中的多种数据样本类型。</p><p>​ 下一个实验随机从AMD数据集中随机抽取了8000个恶意样本，同时从良性数据集中随机抽取了8000个良性样本，共计16000个，形成实验数据集，并按7：3的比例分为训练和测试组。取样时，将原训练组的样品作为训练组进行，并分别采取5轮各取样方法。图5显示分组训练集中前 10 个恶意家族的分布。可见，恶意家族的样本分布极不均衡，第一的家族与第十的家族之间的差距已达十倍左右，更不用说少数恶意家族了。因此，缓解恶意样品的分别失衡是极其重要的。</p><p><img src="https://static-01.hindawi.com/articles/scn/volume-2021/6642252/figures/6642252.fig.005.svgz" alt="图5 前10个家族号码分布"></p><p>​ 此外，对实验中使用的特征进行了过滤，并且使用 <strong>Relief 算法计算每个特征的权重</strong>，并按大到小进行排名。然后，权重大于0.003的特征被选为最终输入特征。特征数量从89756个减少到789个，大大减少了特征冗余，提高了检测效率。</p><p>​ 恶意软件检测是一个分类问题。分类问题存在四个常见指标：准确性、精度、召回率和<em>F-score</em>。恶意样本表示为<em>positive (P)</em>类，良性样本表示为<em>negative (N)</em>类。然后，获得四个评估数值：</p><ol type="1"><li>真阳性 （TP）： 正确预测为阳性的阳性样本数量</li><li>假阴性（FN）：被错误地预测为阴性的阳性样本数量</li><li>假阳性（FP）： 被错误地预测为阳性的阴性样本数量</li><li>真阴性 （TN）： 正确预测为阴性的阴性样本数量</li></ol><p>基于这些数值，以下方程计算四个常见指标： <span class="math display">\[Accuracy = (TP + TN)/(TP + FN + FP + TN) \tag6\]</span></p><p><span class="math display">\[Precision = TP / (TP + FP) \tag7\]</span></p><p><span class="math display">\[Recall = TP / (TP + FN) \tag8\]</span></p><p><span class="math display">\[F-score = \frac{2}{1/precision+1/recall} \tag9\]</span></p><p>​ 精度和召回率相互影响其调和平均值为<em>F</em>- score。</p><p>​ 所有实验均在个人计算机上运行，配备 Intel (R) Core (TM) i7-9700 @ 3.0 GHz CPU，内存为 32 GB，并具有 Windows 10 64 位操作系统。用于评估的软件包括 Python 3.6.1 和 sklearn 0.23.2。</p><h3 id="新抽样战略的执行情况">5.2、新抽样战略的执行情况</h3><p>​ 本文提出的FB2组合方案设计了两种新的基于恶意家族的抽样策略：基于恶意软件家族的等数取样策略和基于恶意软件家族信息的家族抽样策略。为了验证两种取样策略的性能，我们将它们与传统的 Bagging 集成算法进行比较，没有加权投票策略（每个分类器的权重设置为 1，这与传统的袋装集成算法一致），结果见表中<a href="https://www.hindawi.com/journals/scn/2021/6642252/tab1/">1</a>.</p><p><img src="/2021/11/15/FB2Droid/image-20211116162224004.png" alt="图1 采用新的采样策略"></p><p>结果表明，传统的袋装算法在不使用权重的情况下取得了良好的性能，但FB2结成方案的表现得到了进一步的提高。因此，本文中基于恶意家族的两种取样策略有助于缓解恶意样品内部的不平衡，提高检测性能。</p><h3 id="最佳投票权重的性能">5.3、最佳投票权重的性能</h3><p>​ 本文提出的 Bagging 组合方案不仅设计了两种新的抽样策略，而且改进了每个最终基础分类器的组合，即采用加权投票策略进行最终整合。由于不同的采样策略和每轮抽样中选择的不同样本，最终训练的基础分类器也不同，因此每个基础分类器都有自己的偏好或差异。基础分类器之间的差异越明显，最终检测效果越好。因此，本文提出了一个加权投票策略，为每个基础分类器分配最佳权重，以更好地突出每个基础分类器的差异，进一步提高检测性能。本节使用 DE 算法比较 FB2 检测方案，以优化权重与没有正确权重的 FB2（即将每个基本分类器的重量设置为 1结果见表2。</p><p><img src="/2021/11/15/FB2Droid/table2.png" alt="表2 最佳权重的表现"></p><p>​ 从表中可以看到，在给每个基础分类器分配最佳重量后，每个分类器的检测效果得到改善。在没有重量分配的情况下，FB2集成检测方案取得了良好的效果。但是，在使用差分演化算法为每个基础分类器分配最佳权重后，每个检测指标都得到了进一步改进。例如，精度的改进程度至少为 0.005，最多为 0.011。<em>F</em>- 分数至少提高了 0.004， 最高提高了 0.014 。因此，有必要为每个分类器分配适当的权重.</p><h3 id="与基础分类器的比较">5.4、与基础分类器的比较</h3><p>​ 本节评估单个分类器 FB2 的性能改进。因此，FB2 与基础分类器（如 SVM、KNN、DT、LR、LDA 和 MLP）进行了比较。对于每个分类器的参数，使用默认值。表3显示每个基础分类器的实验结果和 FB2 检测结果。</p><p><img src="/2021/11/15/FB2Droid/table3.png" alt="表3 多个基础分类器之间的比较"></p><p>​ 从表3，我们得出以下结论。首先，<strong>只有SVM、KNN、LR等单一分类型号作为分类器，才能达到良好的表现</strong>。然后，在使用 FB2 方案时，表现比单个分类模型显著提高。可以看出，对于所有基础分类器，FB2 使得所有四个效果指标的改进，准确性提高幅度从 1.1% 到 2.3% 不等。精度提高为1.1%至2.3%，F-score改进为0.9%至2.0%。</p><h3 id="与集成分类器的比较">5.5、与集成分类器的比较</h3><p>​ 本节将 FB2 方案与现有集成分类器进行比较。为此，从上面显示的结果中选择结果最差的组，并与现有的集成分类器（如 RF、GBDT 和 AdaBoost）进行比较。对于每个分类器的参数，使用默认值。表4显示结果。虽然基础分类器作为分类器时取得了良好的性能，但与 RF 和其他集成分类器相比，其表现仍然较低。然而，FB2集成方案使用后，其性能得到进一步提高，与集成分类器相比有一定的提高。</p><p><img src="/2021/11/15/FB2Droid/table5.png" alt="表4 多个基础分类器之间的比较"></p><p>​ FB2 使用最无效的基础分类器 DT 与各种集成分类器进行比较。从表中显示的四种类型的评价指标可以看出<a href="https://www.hindawi.com/journals/scn/2021/6642252/tab4/">4</a>，虽然FB2-DT在所有指标中都没有领先，但在大多数情况下仍然是最好的。例如，准确性和<em>F-</em>得分都名列第一，分别为0.978和0.977。因此，一般来说，FB2在一定程度上优于上述三个集成分类器，这证明建议方案的有效性。</p><h3 id="与传统装袋算法的比较">5.6、与传统装袋算法的比较</h3><p>​ 本节将所提出的 FB2 方案与各种单分类器下的传统 Bagging 算法进行比较：SVM、KNN、DT、LR 和 LDA。为了进行更公平的比较，所有分类器都使用默认参数，详细结果见表中。虽然<strong>传统的 Bagging 算法提高了单个分类器的性能，但本文提出的FB2方案的性能得到了进一步的提高</strong>。其中，精度提高 0.2%至1.2%。而且<em>，F-</em>分数提高了0.2%至1.4%。</p><p><img src="/2021/11/15/FB2Droid/table4.png" alt="表5 多个基础分类器之间的比较"></p><p>​ 根据表1和表5，FB2 的性能比传统 Bagging 算法稍差，如果未使用加权投票策略，即未给每个基础分类器最佳权重。但是，在分配最佳权重后，FB2 有显著改进，超过了传统的 Bagging 算法，这进一步证明本文所提出的FB2方案是有效的。</p><h3 id="模型可持续性分析">5.7、模型可持续性分析</h3><p>​ 的确，基于机器学习的探测器肯定会老化，许多学者也在研究相关问题。</p><p>​ 在一些论文中，为了缓解分类器老化问题，他们通过从<strong>Android API关系图中提取的API语义对分类器进行了训练</strong>。API 集群格式中提取的 API 语义可以进一步用于 Android 恶意软件分类器以减慢老化速度。</p><p>​ 但是，本文使用五个特征进行恶意软件检测，并且不单独使用 API 的一个特征，并且每个特征也没有明确的调用关系，如 API，它可防止每种类型的特征的语义提取。还有，徐(K. Xu, Y. Li, R. Deng, K. Chen, and J. Xu, “DroidEvolver: self-evolving android malware detection system" )等人的研究，还基于 API 检测方案，该计划通过不断更新和演变 API 特征集来解决分类器的老化问题。这两种解决方案都使用单个特征进行检测，并且 API 会随着 Android 版本的迭代而更新，而其他特征基本上不会更改，因此仅使用单个特征进行检测将面临更严重的分类器故障问题。并且，使用许多不同类型的特征可以有效地减轻分类器的降解。本文使用了五个不同的特征，并在部分详细描述了这些特征。</p><p>​ 并且，本文中使用的数据集是 AMD，并且样本是在相对较近的时间跨度内收集的。因此，数据集按年份分为七组进行测试，每个数据集被命名为 BM 加年。为了确保实验的公正性，选择了性能最差的基础分类器。为了进行更全面的评估，本文使用<em>F分数指标</em>，即可重复使用性和稳定性均基于<em>F-core</em>，详细结果见表6和7。</p><p><img src="/2021/11/15/FB2Droid/table6.png" alt="表6 FB2 的可重复性"></p><p><img src="/2021/11/15/FB2Droid/table7.png" alt="表7 FB2的稳定性，该FB2在BM10上进行训练，并在其他数据集上进行测试"></p><p>​ 从表6和7，可以得出结论，具有多种特征的FB2在使用旧数据集进行训练和使用新数据集进行测试时，会取得良好的分类结果。FB2的平均可重复利用性约为96.7%，平均稳定性约为95.2%，均超过 DroidSpan。这表明，虽然基于单个动态特征的 DroidSpan 是可持续的，但<strong>基于多个特征的 FB2 非常适合恶意软件更新</strong>，并且具有良好的稳定性。</p><p>​ 综上所述，本文提出的方案在使用许多不同类型的特征的情况下是可防止老化的。</p><h2 id="结论">6、结论</h2><p>​ 本文提出了一种新的基于恶意软件的家族 Bagging 集成方法 （FB2） 和 Android 恶意软件检测方案 （FB2Dorid）。此检测方案由以下步骤组成。首先，<strong>APK 文件被分解以提取特征</strong>。然后，<strong>使用 Relife 特征选择算法来选择一定数量的最重要特征</strong>。其次，提出两种采样策略，即<strong>等量取样和基于家族信息采样</strong>，旨在改进 Bagging 集成算法的采样策略。最后，<strong>将基本分类器与 FB2 相结合</strong>。</p><p>​ 本文旨在验证FB2方案的可行性。实验结果表明，拟议的FB2方案取得了良好的效果。将来，作者将考虑设计新的集成算法，而不仅仅是改进现有的集成算法。此外，希望本文提出的若干抽样策略能真正帮助这一领域的学者。让他们在自己的方案中使用这些取样策略，有效减轻样本不平衡的影响，进一步提高恶意软件检测的准确性；其次，呼吁从事Android恶意软件研究的学者更加关注数据方向或样本失衡。恶意软件虽然增长较快，但与良性应用相比仍然过小，真实数据集和现实检测中的恶意样本数量非常少，恶意软件家族之间的分布差距较大，因此有必要缓解样本失衡。希望有更多的学者从本文中受到启发，提出更好的方案，消除样本失衡带来的负面影响。</p><p>​ 将来，作者会考虑为每个训练子集选择适当的家族信息描述符，并将不同的权重分配给根据每个采样策略训练的基础分类器。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Android Malware</tag>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DroidGraph - Discovering Android Malware by Analyzing Semantic Behavior</title>
    <link href="/2021/11/13/DroidGraph/"/>
    <url>/2021/11/13/DroidGraph/</url>
    
    <content type="html"><![CDATA[<blockquote><p>原文链接：https://ieeexplore.ieee.org/document/6997523</p></blockquote><h2 id="介绍">介绍</h2><p>​ 由于智能手机的普及，手机恶意软件的数量急剧增加。由于智能手机被认定为私人财产，人们在没有意识到手机恶意软件威胁的情况下，储存了敏感数据。这一事实给了攻击者以智能手机为目标的巨大动机，而且事实上，移动恶意软件现在非常猖獗，特别是在最流行的移动平台Android上。</p><p>​ 为了应对日益增长的Android恶意软件的威胁，已经提出了许多对策，但没有一个能够成为根本的解决方案。应对的主要困难是Android恶意软件变种的快速增长。根据赛门铁克的报告，从2012年到2013年，每个恶意软件家族的平均变异数量增加了50%以上，而同一时期的恶意软件家族数量记录了45%的下降。</p><p>​ 这一趋势的主要原因是，<strong>Android恶意软件不断发展</strong>，使用了<strong>代码混淆</strong>或<strong>垃圾代码插入</strong>等逃避技术。攻击者使用该技术可以轻松构建新的恶意软件变体，这些变体使得现有的<em>基于二进制签名或已授予的权限、类名或包名等特征的移动恶意软件解决方案</em>，无法检测当前的Android恶意软件。</p><p>​ 基于此，我们提出了一种基于语义行为分析的Android恶意软件检测机制<strong>DroidGraph</strong>。<strong>DroidGraph</strong>处理的是<strong>API调用</strong>，因为在Android平台中，<strong>API调用</strong>对于Android操作来说占据着重要的位置，而且每个<strong>API调用</strong>都有不同的语义含义。因此，分析Android API调用可以让我们更容易地理解Android恶意软件的企图。我们将从APK文件中提取的<strong>API调用</strong>转换为<strong>层次行为图</strong>。这些图通过分解为<strong>APK层次结构</strong>，分别从<em>每个方法、类、包和应用程序级别的角度</em>表示语义意义。这种分层方法使我们避免了对重新包装的恶意软件的错误警报。在抽取行为图之后，我们选择图作为语义签名来检测未知的恶意软件变体，它们代表了恶意软件族的常见行为。</p><p>​ 为了评估<strong>DroidGraph</strong>，我们使用了现实世界的数据，包括从<strong>Contagio手机网站</strong>收集的260个Android恶意软件，以及从谷歌游戏商店和其他Android市场收集的3623个良性应用程序。在一个实验中，DroidGraph仅使用<strong>40个语义特征</strong>就能达到87%的检测准确率。</p><h2 id="安卓恶意软件检测">安卓恶意软件检测</h2><p>​ 为了设计一个有效的缓解方案，首先我们需要对Android恶意软件及其现象有一个深刻的理解。在本节中，我们将描述近期Android恶意软件的两个主要现象，即<strong>重新包装和变质</strong>。</p><p>​ Android恶意软件用于应用重新包装的目的，以<strong>方便创建和分发</strong>。攻击者通过简单地将攻击模块添加到一个众所周知的应用程序中来构建诱饵应用程序，并将其上传到公开的Android市场，以引诱人们安装他们的传统应用程序。这意味着，当我们分析这种重新包装的恶意软件时，我们应该能够识别出哪个部分是攻击者的财产。</p><p>​ 另一种需要考虑的现象是<strong>变质作用</strong>。众所周知，目前的Android恶意软件利用变形来避免现有的反移动恶意软件解决方案。为了完成这种变形，攻击者通常采用几种技术，如<strong>代码混淆、垃圾代码插入和API替换</strong>。因此，仅考虑Android恶意软件的外观可能会导致严重的误检。为此，我们需要分析Android恶意软件的语义，而不是它的外观。</p><h2 id="droidgraph">DroidGraph</h2><p><img src="/2021/11/13/DroidGraph/fig1.png" alt="图1"></p><p><strong>DroidGraph</strong>是一个利用语义特征检测Android恶意软件的系统。图1(上)描述了DroidGraph如何提取Android恶意软件的语义。</p><p>​ 在第一步，我们使用众所周知的<strong>重新打包工具APKtool从APK文件中提取smali代码</strong>。注意，smali代码形成了一种语法上接近纯源代码的解释性语言，因此构造原始代码的控制流是很有用的。</p><p>​ 在第二步中，我们按照APK层次结构为每个smali代码构建控制流的API调用图。API调用图可以表示为一个有向图<span class="math inline">\(G = (V, E)\)</span>，其中<span class="math inline">\(V\)</span>是API调用的集合，<span class="math inline">\(E\)</span>是<strong>API调用的调用关系集</strong>，<span class="math inline">\(E={(v_i, v_j)|v_i, v_j∈V}\)</span>，其中vi表示调用者，<span class="math inline">\(v_j,v_i\)</span>表示<strong>被调用者</strong>。API调用图还表示每个方法、类和包的行为。</p><p>​ <strong>DroidGraph</strong>的主要新颖之处在于我们<strong>如何使用API调用来表示Android恶意软件的语义</strong>。由于为Android开发者定义了成千上万的API调用，它带来了巨大的图表。分析包含数千个API节点的原始API调用图并不是一种有效的方法，它可能不允许我们清楚地理解图的语义。此外，考虑到我们需要比较图来判断Android恶意软件的情况，图的同构通常被称为np完全问题。</p><p>​ 在此驱动下，我们最终将API调用图转换为语义图，每个API调用根据其语义被替换为语义节点。每个API调用被划分为<strong>34个对象</strong>，其中的对象是<strong>进程、网络、帐户等</strong>。这些对象再次被分为<strong>4种行为</strong>，如<strong>打开、读取、写入和关闭</strong>。因此，<strong>数千个API调用</strong>被转换为<strong>总共136个相同的语义节点</strong>。我们把这种<strong>转换称为语义抽象</strong>。</p><p>​ 图1（底部）展示了一个<strong>抽象的简单</strong>示例，其中包含一个<strong>试图窃取SMS消息的真正恶意活动</strong>。通过语义抽象步骤，最终得到每个APK的语义图。</p><p>​ 语义图为我们提供了以下三个好处。</p><ol type="1"><li><strong>抗重新打包</strong>：语义图在每个层次上都有表示，因此，即使攻击者使用重新打包，DroidGraph也会确定哪些模块或类含有恶意代码。</li><li><strong>抗混淆</strong>：语义图考虑API调用的语义，因此，如果攻击者试图替换API调用，或放置一些垃圾代码，甚至混淆代码本身，DroidGraph提取相同的语义图。</li><li><strong>时间优势</strong>：DroidGraph将图比较开销降低到一个常数时间。与具有多项式时间开销的朴素调用图相比，这在实用性方面是一个很大的优势。</li></ol><p>​ 对于Android恶意软件的检测，DroidGraph需要从现有的已知Android恶意软件中提取语义特征。为此，我们采用<strong>图挖掘方法</strong>，从只包含<strong>Android恶意软件家族中常见的恶意语义图而非普通应用程序的图池中选择签名图</strong>。DroidGraph使用特征图来判断测试应用程序是否包含恶意语义行为。</p><h2 id="实验结果">实验结果</h2><p>​ 为了评估<strong>DroidGraph</strong>的性能，我们对真实的Android应用进行了实验，其中包括260个来自Contagio手机网站的Android恶意软件，以及3623个来自第三方Android market和谷歌play store的良性应用。</p><p><img src="/2021/11/13/DroidGraph/fig2.png" alt="图2"></p><p>​ 在实验中，我们从良性应用中得到16080张图，从Android恶意样本中得到1863张图。通过应用图挖掘，最终得到<strong>335个只出现在Android恶意样本中的唯一图</strong>。图2为Android恶意软件的图覆盖率和累计检测率。单个图的最大覆盖率为85，这意味着单个图可以检测1/3的恶意样本。335个语义行为图的检测准确率可达87%，而仅用40个语义行为图就能得到相同的检测结果。良性应用没有假阳性。</p><h1 id="总结">总结</h1><p>​ DroidGraph是对付复杂的Android恶意软件的有效手段。为了进一步的研究，我们计划在不同层次上通过图匹配来提高检测的准确性，并分析找出最有效的语义特征和策略。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Android Malware</tag>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
